{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/DeepGenerativeModels/blob/master/seminars/seminar-5/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install comet-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/holybayes/hse-gans-ae/6256182115b64046b78525c20030573e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import comet_ml in the top of your file\n",
    "from comet_ml import Experiment\n",
    "    \n",
    "# Add the following code anywhere in your machine learning file\n",
    "experiment = Experiment(api_key=\"lODeHEtCf7XLaV6DJrOfugNcA\",\n",
    "                        project_name=\"hse-gans-ae\", workspace=\"holybayes\")\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "seed=1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "MNIST dataset will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "\n",
    "mnist_transforms = transforms.Compose([ \n",
    "    transforms.ToTensor(), # PIL Image -> Tensor\n",
    "#     transforms.Lambda(lambda x: x/255.), # это уже сделано в мнистовом датасете\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=mnist_transforms),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=mnist_transforms),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4bb088e978>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(train_loader))\n",
    "image.shape\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "indx = 0\n",
    "plt.title(f'MNIST: {label[indx].item()}')\n",
    "plt.imshow(image[indx].squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder model\n",
    "\n",
    "![](http://bjlkeng.github.io/images/autoencoder_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            # define your layers here\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            # define your layers here\n",
    "        )\n",
    "\n",
    "    def encode(self, x): # your code \n",
    "    def decode(self, z): # your code\n",
    "    def forward(self, x): # your code\n",
    "    def sample(self, size): # sample from z and pass through decoder\n",
    "    \n",
    "    @property\n",
    "    def device(self): return next(self.parameters()).device\n",
    "\n",
    "\n",
    "model = AE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 27.8521\n",
      "====> Epoch: 2 Average loss: 11.3696\n",
      "====> Epoch: 3 Average loss: 9.6326\n",
      "====> Epoch: 4 Average loss: 8.7514\n",
      "====> Epoch: 5 Average loss: 8.1574\n",
      "====> Epoch: 6 Average loss: 7.7321\n",
      "====> Epoch: 7 Average loss: 7.4018\n",
      "====> Epoch: 8 Average loss: 7.1234\n",
      "====> Epoch: 9 Average loss: 6.8940\n",
      "====> Epoch: 10 Average loss: 6.7124\n"
     ]
    }
   ],
   "source": [
    "def recon_loss(recon_x, x):\n",
    "    MSE = # YOUR MSE loss\n",
    "    return MSE\n",
    "\n",
    "\n",
    "log_interval=10\n",
    "epochs=10\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        # your code - сбросьте накопленный градиент\n",
    "        recon_batch = # data reconstructed by your model\n",
    "        loss = recon_loss(recon_batch, data)\n",
    "        # your code - сделайте backprop\n",
    "        train_loss += loss.item()\n",
    "        # your code - сделайте градиентный шаг оптимизатором\n",
    "        if batch_idx % log_interval == 0:\n",
    "            experiment.log_metric('ae/train/loss', loss.item() / len(data), step=batch_idx, epoch=epoch)\n",
    "            \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    # your code - посчитайте средний лосс на тестовой выборке\n",
    "    experiment.log_metric('ae/test/loss', test_loss, epoch=epoch)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample_size=64\n",
    "        sample = model.sample(sample_size).cpu()\n",
    "        log_img = make_grid(sample.view(-1,1,28,28)).permute((1,2,0))\n",
    "        experiment.log_image(log_img,name='ae/sample',step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Autoencoder for Distribution Estimation (MADE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** как на выходе автоэнкодера получать честные вероятности пикселей (или цветов), как в PixelCNN?\n",
    "\n",
    "**Идея:** давайте используем тот же трюк с масками. А именно, давайте сделаем так, чтобы каждый выход $\\hat{x}_i$ автоэнкодера зависел только от предыдущих входов $x_{j<i}$\n",
    "\n",
    "![](http://bjlkeng.github.io/images/made_mask.png)\n",
    "\n",
    "**Алгоритм MADE:**\n",
    "1. Пронумеруем нейроны каждого слоя, включая входной. Нейроны входного и выходного слоя будут пронумерованы уникальными значениями от 0 (включая) до D (не включая) (D-число фичей на входе и на выходе)\n",
    "2. Нейроны каждого промежуточного слоя пронумеруем НЕ ОБЯЗАТЕЛЬНО уникальными значениями из диапазона от 0 (включая) до D-1 (не включая)\n",
    "3. Ограничим связи полносвязных слоёв, чтобы каждый нейрон зависел только от \"предыдущих\" (т.е. от нейронов с не большим индексом)\n",
    "\\begin{align*}\n",
    "M^{W^l}_{k', k} = \\left\\{\n",
    "            \\begin{array}{ll}\n",
    "              1 \\text{ if } m^l(k') \\geq m^{l-1}(k)  \\\\\n",
    "              0 \\text{ otherwise}\n",
    "            \\end{array}\n",
    "          \\right. \\\\ \\tag{Inner mask}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "M^{V}_{d, k} = \\left\\{\n",
    "            \\begin{array}{ll}\n",
    "              1 \\text{ if } d > m^{L}(k)  \\\\\n",
    "              0 \\text{ otherwise}\n",
    "            \\end{array}\n",
    "          \\right.  \\\\ \\tag{Output mask}\n",
    "\\end{align*}\n",
    "4. Останется наложить маски матрицы весов (т.е. ограничить нейронные связи) и взять сигмоиду от выхода. Это и будут ***честные обусловленные вероятности***\n",
    "\n",
    "\\begin{align*}\n",
    "{\\bf h}({\\bf x}) &= {\\bf g}({\\bf b} + {\\bf (W \\odot M^W)x}) \\\\\n",
    "{\\hat{\\bf x}} &= \\text{sigm}({\\bf c} + {\\bf (V \\odot M^V)h(x)})  \\tag{Output}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MADE(\n",
       "  (encoder): Sequential(\n",
       "    (0): MaskedLinear(in_features=784, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): MaskedLinear(in_features=400, out_features=20, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): MaskedLinear(in_features=20, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): MaskedLinear(in_features=400, out_features=784, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implements Masked AutoEncoder for Density Estimation, by Germain et al. 2015\n",
    "Re-implementation by Andrej Karpathy based on https://arxiv.org/abs/1502.03509\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class MaskedLinear(nn.Linear):\n",
    "    \"\"\" Такой же полносвязный слой, как дефолтный, только на веса накладываются маски \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__(in_features, out_features, bias)        \n",
    "        self.register_buffer('mask', torch.ones(out_features, in_features))\n",
    "        \n",
    "    def set_mask(self, mask):\n",
    "        self.mask.data.copy_(torch.from_numpy(mask.astype(np.uint8).T))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        masked_weight = ???\n",
    "        return F.linear(input, masked_weight, self.bias)\n",
    "\n",
    "    \n",
    "class MADE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes_encoder, hidden_sizes_decoder, output_size, \n",
    "                 num_masks=1, natural_ordering=False):\n",
    "        \"\"\"\n",
    "        num_masks: can be used to train ensemble over orderings/connections\n",
    "        natural_ordering: force natural ordering of dimensions, don't use random permutations\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes_encoder = hidden_sizes_encoder\n",
    "        self.hidden_sizes_decoder = hidden_sizes_decoder\n",
    "        assert self.output_size % self.input_size == 0, \"nout must be integer multiple of nin\"\n",
    "        \n",
    "        self.encoder = ??? Your code\n",
    "        self.decoder = ??? Your code\n",
    "                \n",
    "        \n",
    "        # seeds for orders/connectivities of the model ensemble\n",
    "        self.natural_ordering = natural_ordering\n",
    "        self.num_masks = num_masks\n",
    "        self.seed = 0 # for cycling through num_masks orderings\n",
    "        \n",
    "        self.m = {}\n",
    "        self.update_masks() # builds the initial self.m connectivity\n",
    "        # note, we could also precompute the masks and cache them, but this\n",
    "        # could get memory expensive for large number of masks.\n",
    "        \n",
    "    def update_masks(self):\n",
    "        # задайте маски для весов энкодера и декодера. Формула выше\n",
    "        ??? Your code\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,784)\n",
    "        return self.decoder(self.encoder(x))\n",
    "    \n",
    "    def sample(self, size):\n",
    "        hidden_dim = self.hidden_sizes_decoder[0]\n",
    "        device = next(model.parameters()).device\n",
    "        x = torch.rand((size,hidden_dim)).to(device)\n",
    "        return F.sigmoid(self.decoder(x))\n",
    "    \n",
    "model = MADE(784, [400,20], [20,400], 784)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 191.9323\n",
      "====> Epoch: 2 Average loss: 140.1041\n",
      "====> Epoch: 3 Average loss: 121.8988\n",
      "====> Epoch: 4 Average loss: 115.4033\n",
      "====> Epoch: 5 Average loss: 112.4706\n",
      "====> Epoch: 6 Average loss: 110.3260\n",
      "====> Epoch: 7 Average loss: 107.4999\n",
      "====> Epoch: 8 Average loss: 104.3590\n",
      "====> Epoch: 9 Average loss: 102.1362\n",
      "====> Epoch: 10 Average loss: 99.4987\n"
     ]
    }
   ],
   "source": [
    "# Your code - обучение то же самое, что и с обычным автоэнкодером. Только замените лосс на кросс-энтропию "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "\n",
    "[simple explanation of MADE and AE](http://bjlkeng.github.io/posts/autoregressive-autoencoders/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
