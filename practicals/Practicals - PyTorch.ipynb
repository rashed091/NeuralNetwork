{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "A tensor is a d-dimensional array and serves as the input and output of every layer of a deep network. Tensors have many mathematical operations associated with them (extensions of matrix multiplication). However, those operations are not used in most deep learning frameworks, and a Tensor is simply an array of numbers.\n",
    "\n",
    "1. https://en.wikipedia.org/wiki/Tensor\n",
    "2. https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [0, 6]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 3, 0],[2, 4, 6]])\n",
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 3, 0],\n",
       "         [2, 4, 6]]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 0, 2, 4, 6])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [0, 2],\n",
       "        [4, 6]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 0],\n",
       "        [2, 4, 6]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 3, 0],\n",
       "         [2, 4, 6]],\n",
       "\n",
       "        [[1, 3, 0],\n",
       "         [2, 4, 6]],\n",
       "\n",
       "        [[1, 3, 0],\n",
       "         [2, 4, 6]]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(1, 2, 3).expand(3, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4042, 0.2023, 0.5143],\n",
       "         [0.8907, 0.9357, 0.0373],\n",
       "         [0.9496, 0.1768, 0.5923]],\n",
       "\n",
       "        [[0.2776, 0.2183, 0.4221],\n",
       "         [0.5166, 0.0942, 0.3265],\n",
       "         [0.8599, 0.4793, 0.2411]],\n",
       "\n",
       "        [[0.9283, 0.0325, 0.3695],\n",
       "         [0.9139, 0.5492, 0.3188],\n",
       "         [0.2296, 0.3747, 0.2233]]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 3, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4042, 0.2023, 0.5143],\n",
       "         [0.2776, 0.2183, 0.4221],\n",
       "         [0.9283, 0.0325, 0.3695]],\n",
       "\n",
       "        [[0.8907, 0.9357, 0.0373],\n",
       "         [0.5166, 0.0942, 0.3265],\n",
       "         [0.9139, 0.5492, 0.3188]],\n",
       "\n",
       "        [[0.9496, 0.1768, 0.5923],\n",
       "         [0.8599, 0.4793, 0.2411],\n",
       "         [0.2296, 0.3747, 0.2233]]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1626, 0.2973, 0.1778],\n",
       "         [0.9956, 0.1095, 0.9746],\n",
       "         [0.3998, 0.8508, 0.2644]],\n",
       "\n",
       "        [[0.9032, 0.4908, 0.7925],\n",
       "         [0.0098, 0.5688, 0.8994],\n",
       "         [0.0382, 0.9372, 0.8715]],\n",
       "\n",
       "        [[0.9011, 0.7393, 0.1442],\n",
       "         [0.3166, 0.2809, 0.7144],\n",
       "         [0.7246, 0.3827, 0.8788]]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.permute(2, 1, 0)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-place operation\n",
    "\n",
    "> All operations end with \"_\" is in place operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0, 3.0])\n",
    "y = torch.tensor([1.0, 4.0])\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out\n",
    "> We can assign the operation result to a variable. Alternatively, all operation methods have an out parameter to store the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-6e15dc36f1f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "r1 = torch.Tensor(2, 3)\n",
    "torch.add(x, y, out=r1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 5., 5.],\n",
       "        [9., 9., 2.],\n",
       "        [0., 0., 8.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.empty(3, 3).random_(10)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 9., 0.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[:, 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 0., 5.],\n",
       "        [9., 0., 2.],\n",
       "        [0., 0., 8.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion between NumPy ndarray and Tensor\n",
    "> During the conversion, both ndarray and Tensor share the same memory storage. Change value from either side will affect the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion\n",
    "a = np.array([1, 2, 3])\n",
    "v = torch.from_numpy(a)         # Convert a numpy array to a Tensor\n",
    "\n",
    "b = v.numpy()                   # Tensor to numpy\n",
    "b[1] = -1                       # Numpy and Tensor share the same memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if a[1] == b[1]:\n",
    "    print('True') # Change Numpy will also change the Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor meta-data\n",
    "\n",
    "> Size of the Tensor and number of elements in Tensor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Basic Tensor operation\n",
    "x = torch.empty(3, 3).fill_(4)\n",
    "x.size()                        # torch.Size([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(x)                  # 6: number of elements in x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape Tensor\n",
    "\n",
    "> Reshape a Tensor to different size:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tensor resizing\n",
    "x = torch.randn(2, 3)            # Size 2x3\n",
    "y = x.view(6)                    # Resize x to size 6\n",
    "z = x.view(-1, 2)                # Size 3x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8635,  0.8067],\n",
       "        [-1.7315,  0.2933],\n",
       "        [ 0.9307,  1.2782]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a random Tensor\n",
    "\n",
    ">To increase the reproducibility of result, we often set the random seed to a specific value first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1f142c6350>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.rand(2, 3)            # Initialize with random number (uniform distribution)\n",
    "v = torch.randn(2, 3)           # With normal distribution (SD=1, mean=0)\n",
    "v = torch.randperm(4)           # Size 4. Random permutation of integers from 0 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 3])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identity matrices, Fill Tensor with 0, 1 or values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 7.7052e+31],\n",
      "        [7.2148e+22, 2.5226e-18, 2.5930e-09],\n",
      "        [1.0413e-11, 3.0883e-09, 4.2731e-05]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(3,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3],\n",
      "        [3, 3]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.full((2,2), 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.eye(3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.ones(3, 2)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3.])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1].fill_(2)\n",
    "v[2].fill_(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [2., 2.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye = torch.eye(3)              # Create an identity 3x3 tensor\n",
    "\n",
    "u = torch.ones_like(eye)        # A tensor with same shape as eye. Fill it with 1.\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6919, -0.4043,  0.2222],\n",
      "        [ 0.5773, -1.7637,  0.2264],\n",
      "        [-0.2355,  0.3019, -0.2770]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 3).normal_()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 3).bernoulli_(.7)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 3).fill_(5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Tensor with a range of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.arange(5)             # similar to range(5) but creating a Tensor\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.arange(0, 6, step=1)  # Size 5. Similar to range(0, 5, 1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = v.view(-1, 3)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.linspace(1, 10, steps=10) # Create a Tensor with 10 linear points for (1, 10) inclusively\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.logspace(start=-10, end=10, steps=5) # Size 5: 1.0e-10 1.0e-05 1.0e+00, 1.0e+05, 1.0e+10\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 6., 9.],\n",
       "        [9., 8., 3.],\n",
       "        [3., 1., 7.]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(3, 3).random_(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 6., 9.],\n",
       "        [9., 8., 3.],\n",
       "        [3., 1., 7.],\n",
       "        [8., 6., 9.],\n",
       "        [9., 8., 3.],\n",
       "        [3., 1., 7.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x, x), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 6., 9., 8., 6., 9.],\n",
       "        [9., 8., 3., 9., 8., 3.],\n",
       "        [3., 1., 7., 3., 1., 7.]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x, x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8., 6., 9.],\n",
       "         [9., 8., 3.],\n",
       "         [3., 1., 7.]],\n",
       "\n",
       "        [[8., 6., 9.],\n",
       "         [9., 8., 3.],\n",
       "         [3., 1., 7.]]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reorganize data element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 8.],\n",
       "        [9., 3.]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(2, 2).random_(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 8.],\n",
       "        [9., 8.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather element\n",
    "# torch.gather(input, dim, index, out=None)\n",
    "\n",
    "torch.gather(x, 0, torch.LongTensor([[0,0],[1,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000e-10, 1.0000e-05]),\n",
       " tensor([1.0000e+00, 1.0000e+05]),\n",
       " tensor([1.0000e+10]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.randn(3, 3)\n",
    "s = torch.chunk(v, 3)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.4771,  0.8310, -0.2477],\n",
       "         [-0.8029,  0.2366,  0.2857]]),\n",
       " tensor([[ 0.6898, -0.6331,  0.8795]]))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(r, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index select, mask select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.arange(9)\n",
    "v = v.view(3, 3)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 2])\n",
    "r = torch.index_select(v, 0, indices) # Select element 0 and 2 for each dimension 1.\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = v.ge(3) ## greater then\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.masked_select(v, mask)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squeeze and unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.],\n",
       "          [1.]]],\n",
       "\n",
       "\n",
       "        [[[1.],\n",
       "          [1.]]]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones(2,1,2,1) # Size 2x1x2x1\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.squeeze(t)     # Size 2x2\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.]]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.squeeze(t, 1)  # Squeeze dimension 1: Size 2x2x1\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un-squeeze a dimension\n",
    "x = torch.Tensor([1, 2, 3])\n",
    "r = torch.unsqueeze(x, 0)       # Size: 1x3\n",
    "r = torch.unsqueeze(x, 1)       # Size: 3x1\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-zero elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [0, 2],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [2, 0],\n",
       "        [2, 1],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4259, 0.7812],\n",
       "        [0.6607, 0.1251]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2x2: A uniform distributed random matrix with range [0, 1]\n",
    "r = torch.Tensor(2, 2).uniform_(0, 1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bernoulli\n",
    "r = torch.bernoulli(r)   # Size: 2x2. Bernoulli with probability p stored in elements of r\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 1])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial\n",
    "w = torch.Tensor([0, 4, 8, 2]) # Create a tensor of weights\n",
    "r = torch.multinomial(w, 4, replacement=True) # Size 4: 3, 2, 1, 2\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "normal() received an invalid combination of arguments - got (int, int), but expected one of:\n * (Tensor mean, Tensor std, *, torch.Generator generator, Tensor out)\n * (Tensor mean, float std, *, torch.Generator generator, Tensor out)\n * (float mean, Tensor std, *, torch.Generator generator, Tensor out)\n * (float mean, float std, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-807887057786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# From 10 means and SD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Size 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: normal() received an invalid combination of arguments - got (int, int), but expected one of:\n * (Tensor mean, Tensor std, *, torch.Generator generator, Tensor out)\n * (Tensor mean, float std, *, torch.Generator generator, Tensor out)\n * (float mean, Tensor std, *, torch.Generator generator, Tensor out)\n * (float mean, float std, tuple of ints size, *, torch.Generator generator, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "# Normal distribution\n",
    "# From 10 means and SD\n",
    "r = torch.normal(1, 0) # Size 10\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random sampling\n",
    "----------------------------------\n",
    "- autofunction:: manual_seed    - Set a manual seed\n",
    "- autofunction:: initial_seed   - Randomize a seed by the system\n",
    "- autofunction:: get_rng_state\n",
    "- autofunction:: set_rng_state\n",
    "- autodata:: default_generator\n",
    "- autofunction:: bernoulli\n",
    "- autofunction:: multinomial\n",
    "- autofunction:: normal\n",
    "- autofunction:: rand\n",
    "- autofunction:: randn\n",
    "- autofunction:: randperm\n",
    "\n",
    "In-place random sampling\n",
    "-------------------------------------\n",
    "\n",
    "There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation:\n",
    "\n",
    "- :func:`torch.Tensor.bernoulli_` - in-place version of :func:`torch.bernoulli`\n",
    "- :func:`torch.Tensor.cauchy_` - numbers drawn from the Cauchy distribution\n",
    "- :func:`torch.Tensor.exponential_` - numbers drawn from the exponential distribution\n",
    "- :func:`torch.Tensor.geometric_` - elements drawn from the geometric distribution\n",
    "- :func:`torch.Tensor.log_normal_` - samples from the log-normal distribution\n",
    "- :func:`torch.Tensor.normal_` - in-place version of :func:`torch.normal`\n",
    "- :func:`torch.Tensor.random_` - numbers sampled from the discrete uniform distribution\n",
    "- :func:`torch.Tensor.uniform_` - numbers sampled from the continuous uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Math operations\n",
    "f= torch.FloatTensor([-1, -2, 3])\n",
    "r = torch.abs(f)      # 1 2 3\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-aa42da0cece4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add x, y and scalar 10 to all elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (6) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# Add x, y and scalar 10 to all elements\n",
    "r = torch.add(x, 10)\n",
    "r = torch.add(x, 10, y)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clamp the value of a Tensor\n",
    "r = torch.clamp(v, min=-0.5, max=0.5)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise divide\n",
    "r = torch.div(v, v+0.03)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise multiple\n",
    "r = torch.mul(v, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Math operations\n",
    "f= torch.FloatTensor([-1, -2, 3])\n",
    "r = torch.abs(f)      # 1 2 3\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pointwise Ops\n",
    "----------------------------------------\n",
    "\n",
    "- autofunction:: abs\n",
    "- autofunction:: acos           - arc cosine\n",
    "- autofunction:: add\n",
    "- autofunction:: addcdiv        - element wise: t1 + s * t2/t3\n",
    "- autofunction:: addcmul        - element wise: t1 + s * t2 * t3\n",
    "- autofunction:: asin           - arc sin\n",
    "- autofunction:: atan\n",
    "- autofunction:: atan2\n",
    "- autofunction:: ceil           - ceiling\n",
    "- autofunction:: clamp          - clamp elements into a range\n",
    "- autofunction:: cos\n",
    "- autofunction:: cosh\n",
    "- autofunction:: div            - divide\n",
    "- autofunction:: erf            - Gaussian error functiom\n",
    "- autofunction:: erfinv         - Inverse\n",
    "- autofunction:: exp\n",
    "- autofunction:: expm1          - exponential of each element minus 1\n",
    "- autofunction:: floor          \n",
    "- autofunction:: fmod           - element wise remainder of division\n",
    "- autofunction:: frac           - fraction part 3.4 -> 0.4\n",
    "- autofunction:: lerp           - linear interpolation\n",
    "- autofunction:: log            - natural log\n",
    "- autofunction:: log1p          - y = log(1 + x)\n",
    "- autofunction:: mul            - multiple\n",
    "- autofunction:: neg \n",
    "- autofunction:: pow\n",
    "- autofunction:: reciprocal     - 1/x\n",
    "- autofunction:: remainder      - remainder of division\n",
    "- autofunction:: round\n",
    "- autofunction:: rsqrt          - the reciprocal of the square-root \n",
    "- autofunction:: sigmoid        - sigmode(x)\n",
    "- autofunction:: sign\n",
    "- autofunction:: sin\n",
    "- autofunction:: sinh\n",
    "- autofunction:: sqrt\n",
    "- autofunction:: tan\n",
    "- autofunction:: tanh\n",
    "- autofunction:: trunc          - truncated integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduction operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.arange(9, dtype=torch.float64)\n",
    "v = v.view(3, 3)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  5.,  7.],\n",
       "        [ 9., 12., 15.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.cumsum(v, dim=0)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.], dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(v, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3, 12, 21])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 12., 15.], dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "x.norm(p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduction Ops\n",
    "--------------------------\n",
    "\n",
    "- autofunction:: cumprod        - accumulate product of elements x1*x2*x3...\n",
    "- autofunction:: cumsum\n",
    "- autofunction:: dist           - L-p norm\n",
    "- autofunction:: mean\n",
    "- autofunction:: median\n",
    "- autofunction:: mode\n",
    "- autofunction:: norm           - L-p norm\n",
    "- autofunction:: prod           - accumulate product\n",
    "- autofunction:: std            - compute standard deviation\n",
    "- autofunction:: sum\n",
    "- autofunction:: var            - variance of all elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Comparison\n",
    "# Size 3x3: Element-wise comparison\n",
    "r = torch.eq(v, v)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 5, 8]), tensor([2, 2, 2]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max element with corresponding index\n",
    "r = torch.max(v, 1)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison Ops\n",
    "-----------------------\n",
    "\n",
    "- autofunction:: eq             - Compare elements\n",
    "- autofunction:: equal          - True of 2 tensors are the same \n",
    "- autofunction:: ge             - Element-wise greater or equal comparison\n",
    "- autofunction:: gt\n",
    "- autofunction:: kthvalue       - k-th element\n",
    "- autofunction:: le\n",
    "- autofunction:: lt\n",
    "- autofunction:: max\n",
    "- autofunction:: min\n",
    "- autofunction:: ne\n",
    "- autofunction:: sort\n",
    "- autofunction:: topk           - top k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix, vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.dot(torch.tensor([4, 2]), torch.tensor([3, 1]))\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8317,  0.8934])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.randn(2, 4)\n",
    "vec = torch.randn(4)\n",
    "r = torch.mv(mat, vec)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5831, -4.9747])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix + Matrix X vector\n",
    "# Size 2\n",
    "M = torch.randn(2)\n",
    "mat = torch.randn(2, 3)\n",
    "vec = torch.randn(3)\n",
    "r = torch.addmv(M, mat, vec)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4561,  0.2306,  0.4803,  0.1904],\n",
       "        [-0.5957, -0.9246, -1.1840, -0.2337]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix x Matrix\n",
    "# Size 2x4\n",
    "mat1 = torch.randn(2, 3)\n",
    "mat2 = torch.randn(3, 4)\n",
    "r = torch.mm(mat1, mat2)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2168,  2.2809,  0.7730, -1.0231],\n",
       "        [-0.3334,  0.1540,  0.0586, -0.6885],\n",
       "        [ 1.4199, -1.0344, -1.5947,  1.2797]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix + Matrix X Matrix\n",
    "# Size 3x4\n",
    "M = torch.randn(3, 4)\n",
    "mat1 = torch.randn(3, 2)\n",
    "mat2 = torch.randn(2, 4)\n",
    "r = torch.addmm(M, mat1, mat2)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross product\n",
    "m1 = torch.ones(3, 5)\n",
    "m2 = torch.ones(3, 5)\n",
    "\n",
    "# Cross product\n",
    "# Size 3x5\n",
    "r = torch.cross(m1, m2)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 1., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.histc(torch.FloatTensor([1, 2, 1]), bins=4, min=0, max=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0797,  0.3801,  0.2044],\n",
       "        [-0.2176, -0.2718, -0.5107],\n",
       "        [ 0.1909,  0.0479,  0.7612]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renormalization\n",
    "v = torch.randn(3,3)\n",
    "r = torch.renorm(v, 1, 0, 1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0797, -0.8637,  1.6980])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.diag(v)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7546)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0797,  0.0000,  0.0000],\n",
       "        [-0.6914, -0.8637,  0.0000],\n",
       "        [ 0.4259,  0.1068,  1.6980]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0797,  0.3801,  0.2044],\n",
       "        [ 0.0000, -0.8637, -1.6228],\n",
       "        [ 0.0000,  0.0000,  1.6980]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors\n",
    "----------------------------------\n",
    "- autofunction:: is_tensor\n",
    "- autofunction:: is_storage\n",
    "- autofunction:: set_default_tensor_type\n",
    "- autofunction:: numel\n",
    "- autofunction:: set_printoptions\n",
    "\n",
    "Serialization\n",
    "----------------------------------\n",
    "- autofunction:: save          - Saves an object to a disk file\n",
    "- autofunction:: load          - Loads an object saved with torch.save() from a file\n",
    "\n",
    "Parallelism\n",
    "----------------------------------\n",
    "- autofunction:: get_num_threads - Gets the number of OpenMP threads used for parallelizing CPU operations\n",
    "- autofunction:: set_num_threads\n",
    "\n",
    "Spectral Ops\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "- autofunction:: stft          - Short-time Fourier transform \n",
    "- autofunction:: hann_window   - Hann window function\n",
    "- autofunction:: hamming_window  - Hamming window function\n",
    "- autofunction:: bartlett_window - Bartlett window function\n",
    "\n",
    "\n",
    "BLAS and LAPACK Operations\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "- autofunction:: addbmm          - Batch add and mulitply matrices nxp + bnm X bmp -> bxnxp\n",
    "- autofunction:: addmm           - Add and mulitply matrices nxp + nm X mp -> nxp\n",
    "- autofunction:: addmv           - Add and matrix, vector multipy n + nxm X m -> n\n",
    "- autofunction:: addr            - Outer product of vectors\n",
    "- autofunction:: baddbmm         - Batch add and mulitply matrices\n",
    "- autofunction:: bmm             - Batch mulitply matrices bnm X bmp -> bnp\n",
    "- autofunction:: btrifact        - LU factorization\n",
    "- autofunction:: btrifact_with_info\n",
    "- autofunction:: btrisolve\n",
    "- autofunction:: btriunpack\n",
    "- autofunction:: dot             - Dot product of 2 tensors\n",
    "- autofunction:: eig             - Eigenvalues and eigenvectors ofsquare matrix\n",
    "- autofunction:: gels            - Solution for least square or p-norm(AX - B)\n",
    "- autofunction:: geqrf\n",
    "- autofunction:: ger             - Outer product of 2 vectors\n",
    "- autofunction:: gesv            - Solve linear equations\n",
    "- autofunction:: inverse         - Inverse of square matrix\n",
    "- autofunction:: det             - Determinant of a 2D square Variable\n",
    "- autofunction:: matmul          - Matrix product of tensors\n",
    "- autofunction:: mm\t\t\t\t- Matrix multiplication\n",
    "- autofunction:: mv              - Matrix vector product\n",
    "- autofunction:: orgqr           - Orthogal matrix Q \n",
    "- autofunction:: ormqr           - Multiplies matrix by the orthogonal Q matrix\n",
    "- autofunction:: potrf           - Cholesky decomposition\n",
    "- autofunction:: potri           - Inverse of a positive semidefinite matrix with Cholesky\n",
    "- autofunction:: potrs           - Solve linear equation with positive semidefinite\n",
    "- autofunction:: pstrf           - Cholesky decomposition of a positive semidefinite matrix\n",
    "- autofunction:: qr              - QR decomposition\n",
    "- autofunction:: svd             - SVD decomposition\n",
    "- autofunction:: symeig          - Eigenvalues and eigenvectors\n",
    "- autofunction:: trtrs           - Solves a system of equations with a triangular coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6., -4.,  6., -4.,  6.],\n",
      "        [ 7., -3.,  7., -3.,  7.],\n",
      "        [ 8., -2.,  8., -2.,  8.],\n",
      "        [ 9., -1.,  9., -1.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1.], [2.], [3.], [4.]])\n",
    "B = torch.tensor([[5., -5., 5., -5., 5.]])\n",
    "C = A + B\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " q = torch.arange(0, 20, dtype=torch.float32).storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0\n",
      " 1.0\n",
      " 2.0\n",
      " 3.0\n",
      " 4.0\n",
      " 5.0\n",
      " 6.0\n",
      " 7.0\n",
      " 8.0\n",
      " 9.0\n",
      " 10.0\n",
      " 11.0\n",
      " 12.0\n",
      " 13.0\n",
      " 14.0\n",
      " 15.0\n",
      " 16.0\n",
      " 17.0\n",
      " 18.0\n",
      " 19.0\n",
      "[torch.FloatStorage of size 20]\n"
     ]
    }
   ],
   "source": [
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "n = torch.linspace(1, 4, 4)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 4., 8.],\n",
       "        [6., 8., 9.],\n",
       "        [4., 5., 0.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.empty(3, 3).random_(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Variable** wraps a Tensor. It supports nearly all the API defined by a Tensor. \n",
    "Variable also provides a _backward_ method to perform backpropagation. For example, \n",
    "to backpropagate a loss function to train model parameter $x$, we use a variable $loss$ \n",
    "to store the value computed by a loss function. Then, we call _loss.backward_ which computes \n",
    "the gradients $$\\frac{\\partial loss}{\\partial x}$$ for all trainable parameters. \n",
    "PyTorch will store the gradient results back in the corresponding variable $x$.\n",
    "\n",
    "> Create a 2x2 Variable to store input data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$requires\\_grad$ indicates whether a variable is trainable. By default, $requires\\_grad$ is False in creating a Variable. If one of the input to an operation requires gradient, its output and its subgraphs will also require gradient. To fine tune just part of a pre-trained model, we can set $requires\\_grad$ to False at the base but then turn it on at the entrance of the subgraphs that we want to retrain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute gradient\n",
    "Autograd is a PyTorch package for the differentiation for all operations on Tensors. It performs the backpropagation starting from a variable. In deep learning, this variable often holds the value of the cost function. _backward_ executes the backward pass and computes all the backpropagation gradients automatically. We access indvidual gradient through the attributes _grad_ of a variable.  _x.grad_ below returns a 2x2 gradient tensor for $$\\frac{\\partial out}{\\partial x}$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "y.backward()\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To check the resule, we compute the gradient manually:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{split}\n",
    "\\frac{\\partial out}{\\partial x_i} & = \\frac{1}{4} \\sum_j \\frac{\\partial z_j}{\\partial x_i} \\\\\n",
    "& = \\frac{1}{4} \\sum_j \\frac{\\partial 2 y_j^2}{\\partial x_i} \\\\\n",
    "& = \\frac{1}{4} \\sum_j 4 y_j \\frac{\\partial y_j }{\\partial x_i} \\\\\n",
    "& = \\sum_j  (x_j + 2) \\frac{\\partial (x_j + 2) }{\\partial x_i} \\\\\n",
    "& = x_i + 2 \\quad \\quad  & \\frac{\\partial x_j }{\\partial x_i} = 0 \\text{ if } i \\neq j \\\\\n",
    "& = 3 \\quad \\quad  & \\text{ for } x_i=1\\\\\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic vs Static computation graph (PyTorch vs TensorFlow)\n",
    "\n",
    "The TensorFlow computation graph is static. Operation executions are delayed until the graph is completed. TensorFlow defines a graph first with placeholders. Once all operations are added, we execute the graph in a session by feeding data into the placeholders. The computation graph is static because it cannot be changed afterwards. We can repeat this process with different batch of data but the graph remains the same.\n",
    "\n",
    "By design, PyTorch uses a dynamic computation graph. Whenever we create a variable or operations, it is executed immediately. We can add and execute operations anytime before _backward_ is called. _backwards_ follows the graph backward to compute the gradients. Then the graph will be disposed. (the retain_graph flag can override this behavior but rarely suggested.) For the training data in the next training iteration, a new graph is created. We can use the same code to create the same structure, or create a graph with different operations. In NLP, we deal with variable length sentences. Instead of padding the sentence to a fixed length, we create graphs with different number of LSTM cells based on the sentence's length. \n",
    "\n",
    "We call this a define-by-run framework. which the backpropagation is based on what has been running in the graph. Since we start a new graph for every iteration, the backpropagation path can be different for each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "PyTorch provides functions to make training easier without processing the raw data of the gradients directly. This is demonstrated [here.](https://jhui.github.io/2018/02/09/PyTorch-neural-networks/)\n",
    "\n",
    "But to tie all the APIs together, here is an example in doing backpropagation manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/newscred/.local/share/virtualenvs/NeuralNetwork-ojJRyCcG/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(27975546.)\n",
      "1 tensor(22730596.)\n",
      "2 tensor(21506468.)\n",
      "3 tensor(20818208.)\n",
      "4 tensor(18978276.)\n",
      "5 tensor(15495289.)\n",
      "6 tensor(11307624.)\n",
      "7 tensor(7492934.)\n",
      "8 tensor(4719343.)\n",
      "9 tensor(2940541.2500)\n",
      "10 tensor(1884401.8750)\n",
      "11 tensor(1268892.5000)\n",
      "12 tensor(906192.7500)\n",
      "13 tensor(683955.4375)\n",
      "14 tensor(540437.8750)\n",
      "15 tensor(442071.3438)\n",
      "16 tensor(370744.7500)\n",
      "17 tensor(316360.4375)\n",
      "18 tensor(273224.0938)\n",
      "19 tensor(238040.6250)\n",
      "20 tensor(208771.6250)\n",
      "21 tensor(184032.7969)\n",
      "22 tensor(162902.6094)\n",
      "23 tensor(144708.4844)\n",
      "24 tensor(128949.0625)\n",
      "25 tensor(115219.4922)\n",
      "26 tensor(103188.2109)\n",
      "27 tensor(92631.8047)\n",
      "28 tensor(83351.3594)\n",
      "29 tensor(75142.6875)\n",
      "30 tensor(67857.2891)\n",
      "31 tensor(61379.0078)\n",
      "32 tensor(55603.4688)\n",
      "33 tensor(50451.3242)\n",
      "34 tensor(45845.5820)\n",
      "35 tensor(41714.2422)\n",
      "36 tensor(38000.4180)\n",
      "37 tensor(34660.5273)\n",
      "38 tensor(31650.2188)\n",
      "39 tensor(28933.5039)\n",
      "40 tensor(26476.6816)\n",
      "41 tensor(24253.8672)\n",
      "42 tensor(22240.4160)\n",
      "43 tensor(20412.1230)\n",
      "44 tensor(18749.7207)\n",
      "45 tensor(17238.4492)\n",
      "46 tensor(15861.8848)\n",
      "47 tensor(14606.6826)\n",
      "48 tensor(13460.5859)\n",
      "49 tensor(12414.3613)\n",
      "50 tensor(11459.6094)\n",
      "51 tensor(10584.6777)\n",
      "52 tensor(9783.3203)\n",
      "53 tensor(9048.5225)\n",
      "54 tensor(8374.4092)\n",
      "55 tensor(7755.4458)\n",
      "56 tensor(7186.2739)\n",
      "57 tensor(6662.8970)\n",
      "58 tensor(6180.8779)\n",
      "59 tensor(5736.8740)\n",
      "60 tensor(5327.0605)\n",
      "61 tensor(4948.8184)\n",
      "62 tensor(4599.6436)\n",
      "63 tensor(4277.2100)\n",
      "64 tensor(3979.2068)\n",
      "65 tensor(3703.3704)\n",
      "66 tensor(3448.1519)\n",
      "67 tensor(3211.7493)\n",
      "68 tensor(2992.6711)\n",
      "69 tensor(2789.8020)\n",
      "70 tensor(2601.5564)\n",
      "71 tensor(2426.7239)\n",
      "72 tensor(2264.4045)\n",
      "73 tensor(2113.6775)\n",
      "74 tensor(1973.6495)\n",
      "75 tensor(1843.4263)\n",
      "76 tensor(1722.2681)\n",
      "77 tensor(1609.2666)\n",
      "78 tensor(1504.0692)\n",
      "79 tensor(1406.1688)\n",
      "80 tensor(1314.9993)\n",
      "81 tensor(1230.1901)\n",
      "82 tensor(1151.0820)\n",
      "83 tensor(1077.2953)\n",
      "84 tensor(1008.4853)\n",
      "85 tensor(944.2784)\n",
      "86 tensor(884.3829)\n",
      "87 tensor(828.4567)\n",
      "88 tensor(776.2310)\n",
      "89 tensor(727.4592)\n",
      "90 tensor(681.8853)\n",
      "91 tensor(639.3020)\n",
      "92 tensor(599.4960)\n",
      "93 tensor(562.2892)\n",
      "94 tensor(527.5187)\n",
      "95 tensor(494.9816)\n",
      "96 tensor(464.5324)\n",
      "97 tensor(436.0287)\n",
      "98 tensor(409.3442)\n",
      "99 tensor(384.3614)\n",
      "100 tensor(360.9674)\n",
      "101 tensor(339.0456)\n",
      "102 tensor(318.5068)\n",
      "103 tensor(299.2783)\n",
      "104 tensor(281.2333)\n",
      "105 tensor(264.3182)\n",
      "106 tensor(248.4506)\n",
      "107 tensor(233.5718)\n",
      "108 tensor(219.6250)\n",
      "109 tensor(206.5393)\n",
      "110 tensor(194.2471)\n",
      "111 tensor(182.7058)\n",
      "112 tensor(171.8722)\n",
      "113 tensor(161.7022)\n",
      "114 tensor(152.1523)\n",
      "115 tensor(143.1848)\n",
      "116 tensor(134.7594)\n",
      "117 tensor(126.8462)\n",
      "118 tensor(119.4081)\n",
      "119 tensor(112.4215)\n",
      "120 tensor(105.8508)\n",
      "121 tensor(99.6767)\n",
      "122 tensor(93.8719)\n",
      "123 tensor(88.4158)\n",
      "124 tensor(83.2907)\n",
      "125 tensor(78.4603)\n",
      "126 tensor(73.9190)\n",
      "127 tensor(69.6464)\n",
      "128 tensor(65.6284)\n",
      "129 tensor(61.8463)\n",
      "130 tensor(58.2886)\n",
      "131 tensor(54.9394)\n",
      "132 tensor(51.7868)\n",
      "133 tensor(48.8191)\n",
      "134 tensor(46.0250)\n",
      "135 tensor(43.3934)\n",
      "136 tensor(40.9160)\n",
      "137 tensor(38.5857)\n",
      "138 tensor(36.3891)\n",
      "139 tensor(34.3208)\n",
      "140 tensor(32.3733)\n",
      "141 tensor(30.5368)\n",
      "142 tensor(28.8053)\n",
      "143 tensor(27.1750)\n",
      "144 tensor(25.6388)\n",
      "145 tensor(24.1904)\n",
      "146 tensor(22.8250)\n",
      "147 tensor(21.5382)\n",
      "148 tensor(20.3253)\n",
      "149 tensor(19.1819)\n",
      "150 tensor(18.1039)\n",
      "151 tensor(17.0876)\n",
      "152 tensor(16.1292)\n",
      "153 tensor(15.2258)\n",
      "154 tensor(14.3730)\n",
      "155 tensor(13.5703)\n",
      "156 tensor(12.8125)\n",
      "157 tensor(12.0975)\n",
      "158 tensor(11.4228)\n",
      "159 tensor(10.7863)\n",
      "160 tensor(10.1858)\n",
      "161 tensor(9.6192)\n",
      "162 tensor(9.0843)\n",
      "163 tensor(8.5800)\n",
      "164 tensor(8.1039)\n",
      "165 tensor(7.6546)\n",
      "166 tensor(7.2307)\n",
      "167 tensor(6.8303)\n",
      "168 tensor(6.4527)\n",
      "169 tensor(6.0962)\n",
      "170 tensor(5.7600)\n",
      "171 tensor(5.4428)\n",
      "172 tensor(5.1426)\n",
      "173 tensor(4.8594)\n",
      "174 tensor(4.5917)\n",
      "175 tensor(4.3388)\n",
      "176 tensor(4.1005)\n",
      "177 tensor(3.8754)\n",
      "178 tensor(3.6626)\n",
      "179 tensor(3.4616)\n",
      "180 tensor(3.2718)\n",
      "181 tensor(3.0925)\n",
      "182 tensor(2.9232)\n",
      "183 tensor(2.7632)\n",
      "184 tensor(2.6121)\n",
      "185 tensor(2.4694)\n",
      "186 tensor(2.3346)\n",
      "187 tensor(2.2074)\n",
      "188 tensor(2.0871)\n",
      "189 tensor(1.9731)\n",
      "190 tensor(1.8658)\n",
      "191 tensor(1.7642)\n",
      "192 tensor(1.6681)\n",
      "193 tensor(1.5774)\n",
      "194 tensor(1.4917)\n",
      "195 tensor(1.4108)\n",
      "196 tensor(1.3342)\n",
      "197 tensor(1.2617)\n",
      "198 tensor(1.1934)\n",
      "199 tensor(1.1287)\n",
      "200 tensor(1.0675)\n",
      "201 tensor(1.0098)\n",
      "202 tensor(0.9553)\n",
      "203 tensor(0.9037)\n",
      "204 tensor(0.8548)\n",
      "205 tensor(0.8087)\n",
      "206 tensor(0.7650)\n",
      "207 tensor(0.7237)\n",
      "208 tensor(0.6847)\n",
      "209 tensor(0.6478)\n",
      "210 tensor(0.6129)\n",
      "211 tensor(0.5799)\n",
      "212 tensor(0.5486)\n",
      "213 tensor(0.5191)\n",
      "214 tensor(0.4912)\n",
      "215 tensor(0.4648)\n",
      "216 tensor(0.4399)\n",
      "217 tensor(0.4163)\n",
      "218 tensor(0.3940)\n",
      "219 tensor(0.3729)\n",
      "220 tensor(0.3529)\n",
      "221 tensor(0.3340)\n",
      "222 tensor(0.3160)\n",
      "223 tensor(0.2991)\n",
      "224 tensor(0.2831)\n",
      "225 tensor(0.2680)\n",
      "226 tensor(0.2536)\n",
      "227 tensor(0.2401)\n",
      "228 tensor(0.2273)\n",
      "229 tensor(0.2151)\n",
      "230 tensor(0.2036)\n",
      "231 tensor(0.1928)\n",
      "232 tensor(0.1826)\n",
      "233 tensor(0.1728)\n",
      "234 tensor(0.1636)\n",
      "235 tensor(0.1549)\n",
      "236 tensor(0.1466)\n",
      "237 tensor(0.1388)\n",
      "238 tensor(0.1314)\n",
      "239 tensor(0.1245)\n",
      "240 tensor(0.1178)\n",
      "241 tensor(0.1116)\n",
      "242 tensor(0.1057)\n",
      "243 tensor(0.1001)\n",
      "244 tensor(0.0948)\n",
      "245 tensor(0.0897)\n",
      "246 tensor(0.0850)\n",
      "247 tensor(0.0805)\n",
      "248 tensor(0.0762)\n",
      "249 tensor(0.0722)\n",
      "250 tensor(0.0684)\n",
      "251 tensor(0.0648)\n",
      "252 tensor(0.0614)\n",
      "253 tensor(0.0581)\n",
      "254 tensor(0.0550)\n",
      "255 tensor(0.0521)\n",
      "256 tensor(0.0494)\n",
      "257 tensor(0.0468)\n",
      "258 tensor(0.0443)\n",
      "259 tensor(0.0420)\n",
      "260 tensor(0.0398)\n",
      "261 tensor(0.0377)\n",
      "262 tensor(0.0357)\n",
      "263 tensor(0.0338)\n",
      "264 tensor(0.0321)\n",
      "265 tensor(0.0304)\n",
      "266 tensor(0.0288)\n",
      "267 tensor(0.0273)\n",
      "268 tensor(0.0258)\n",
      "269 tensor(0.0245)\n",
      "270 tensor(0.0232)\n",
      "271 tensor(0.0220)\n",
      "272 tensor(0.0209)\n",
      "273 tensor(0.0198)\n",
      "274 tensor(0.0187)\n",
      "275 tensor(0.0178)\n",
      "276 tensor(0.0169)\n",
      "277 tensor(0.0160)\n",
      "278 tensor(0.0151)\n",
      "279 tensor(0.0144)\n",
      "280 tensor(0.0136)\n",
      "281 tensor(0.0129)\n",
      "282 tensor(0.0122)\n",
      "283 tensor(0.0116)\n",
      "284 tensor(0.0110)\n",
      "285 tensor(0.0105)\n",
      "286 tensor(0.0099)\n",
      "287 tensor(0.0094)\n",
      "288 tensor(0.0089)\n",
      "289 tensor(0.0085)\n",
      "290 tensor(0.0081)\n",
      "291 tensor(0.0076)\n",
      "292 tensor(0.0073)\n",
      "293 tensor(0.0069)\n",
      "294 tensor(0.0066)\n",
      "295 tensor(0.0062)\n",
      "296 tensor(0.0059)\n",
      "297 tensor(0.0056)\n",
      "298 tensor(0.0053)\n",
      "299 tensor(0.0051)\n",
      "300 tensor(0.0048)\n",
      "301 tensor(0.0046)\n",
      "302 tensor(0.0044)\n",
      "303 tensor(0.0042)\n",
      "304 tensor(0.0040)\n",
      "305 tensor(0.0038)\n",
      "306 tensor(0.0036)\n",
      "307 tensor(0.0034)\n",
      "308 tensor(0.0032)\n",
      "309 tensor(0.0031)\n",
      "310 tensor(0.0029)\n",
      "311 tensor(0.0028)\n",
      "312 tensor(0.0027)\n",
      "313 tensor(0.0025)\n",
      "314 tensor(0.0024)\n",
      "315 tensor(0.0023)\n",
      "316 tensor(0.0022)\n",
      "317 tensor(0.0021)\n",
      "318 tensor(0.0020)\n",
      "319 tensor(0.0019)\n",
      "320 tensor(0.0018)\n",
      "321 tensor(0.0018)\n",
      "322 tensor(0.0017)\n",
      "323 tensor(0.0016)\n",
      "324 tensor(0.0015)\n",
      "325 tensor(0.0015)\n",
      "326 tensor(0.0014)\n",
      "327 tensor(0.0014)\n",
      "328 tensor(0.0013)\n",
      "329 tensor(0.0012)\n",
      "330 tensor(0.0012)\n",
      "331 tensor(0.0011)\n",
      "332 tensor(0.0011)\n",
      "333 tensor(0.0011)\n",
      "334 tensor(0.0010)\n",
      "335 tensor(0.0010)\n",
      "336 tensor(0.0009)\n",
      "337 tensor(0.0009)\n",
      "338 tensor(0.0009)\n",
      "339 tensor(0.0008)\n",
      "340 tensor(0.0008)\n",
      "341 tensor(0.0008)\n",
      "342 tensor(0.0007)\n",
      "343 tensor(0.0007)\n",
      "344 tensor(0.0007)\n",
      "345 tensor(0.0007)\n",
      "346 tensor(0.0006)\n",
      "347 tensor(0.0006)\n",
      "348 tensor(0.0006)\n",
      "349 tensor(0.0006)\n",
      "350 tensor(0.0005)\n",
      "351 tensor(0.0005)\n",
      "352 tensor(0.0005)\n",
      "353 tensor(0.0005)\n",
      "354 tensor(0.0005)\n",
      "355 tensor(0.0005)\n",
      "356 tensor(0.0004)\n",
      "357 tensor(0.0004)\n",
      "358 tensor(0.0004)\n",
      "359 tensor(0.0004)\n",
      "360 tensor(0.0004)\n",
      "361 tensor(0.0004)\n",
      "362 tensor(0.0004)\n",
      "363 tensor(0.0004)\n",
      "364 tensor(0.0003)\n",
      "365 tensor(0.0003)\n",
      "366 tensor(0.0003)\n",
      "367 tensor(0.0003)\n",
      "368 tensor(0.0003)\n",
      "369 tensor(0.0003)\n",
      "370 tensor(0.0003)\n",
      "371 tensor(0.0003)\n",
      "372 tensor(0.0003)\n",
      "373 tensor(0.0003)\n",
      "374 tensor(0.0003)\n",
      "375 tensor(0.0002)\n",
      "376 tensor(0.0002)\n",
      "377 tensor(0.0002)\n",
      "378 tensor(0.0002)\n",
      "379 tensor(0.0002)\n",
      "380 tensor(0.0002)\n",
      "381 tensor(0.0002)\n",
      "382 tensor(0.0002)\n",
      "383 tensor(0.0002)\n",
      "384 tensor(0.0002)\n",
      "385 tensor(0.0002)\n",
      "386 tensor(0.0002)\n",
      "387 tensor(0.0002)\n",
      "388 tensor(0.0002)\n",
      "389 tensor(0.0002)\n",
      "390 tensor(0.0002)\n",
      "391 tensor(0.0002)\n",
      "392 tensor(0.0002)\n",
      "393 tensor(0.0002)\n",
      "394 tensor(0.0002)\n",
      "395 tensor(0.0001)\n",
      "396 tensor(0.0001)\n",
      "397 tensor(0.0001)\n",
      "398 tensor(0.0001)\n",
      "399 tensor(0.0001)\n",
      "400 tensor(0.0001)\n",
      "401 tensor(0.0001)\n",
      "402 tensor(0.0001)\n",
      "403 tensor(0.0001)\n",
      "404 tensor(0.0001)\n",
      "405 tensor(0.0001)\n",
      "406 tensor(0.0001)\n",
      "407 tensor(0.0001)\n",
      "408 tensor(0.0001)\n",
      "409 tensor(0.0001)\n",
      "410 tensor(0.0001)\n",
      "411 tensor(0.0001)\n",
      "412 tensor(0.0001)\n",
      "413 tensor(0.0001)\n",
      "414 tensor(0.0001)\n",
      "415 tensor(0.0001)\n",
      "416 tensor(0.0001)\n",
      "417 tensor(0.0001)\n",
      "418 tensor(0.0001)\n",
      "419 tensor(0.0001)\n",
      "420 tensor(0.0001)\n",
      "421 tensor(0.0001)\n",
      "422 tensor(0.0001)\n",
      "423 tensor(0.0001)\n",
      "424 tensor(0.0001)\n",
      "425 tensor(0.0001)\n",
      "426 tensor(0.0001)\n",
      "427 tensor(0.0001)\n",
      "428 tensor(0.0001)\n",
      "429 tensor(0.0001)\n",
      "430 tensor(0.0001)\n",
      "431 tensor(0.0001)\n",
      "432 tensor(0.0001)\n",
      "433 tensor(0.0001)\n",
      "434 tensor(0.0001)\n",
      "435 tensor(0.0001)\n",
      "436 tensor(0.0001)\n",
      "437 tensor(0.0001)\n",
      "438 tensor(0.0001)\n",
      "439 tensor(0.0001)\n",
      "440 tensor(0.0001)\n",
      "441 tensor(0.0001)\n",
      "442 tensor(0.0001)\n",
      "443 tensor(0.0001)\n",
      "444 tensor(0.0001)\n",
      "445 tensor(0.0001)\n",
      "446 tensor(0.0001)\n",
      "447 tensor(0.0001)\n",
      "448 tensor(0.0001)\n",
      "449 tensor(0.0001)\n",
      "450 tensor(0.0001)\n",
      "451 tensor(0.0001)\n",
      "452 tensor(0.0001)\n",
      "453 tensor(0.0001)\n",
      "454 tensor(0.0001)\n",
      "455 tensor(0.0000)\n",
      "456 tensor(0.0000)\n",
      "457 tensor(0.0000)\n",
      "458 tensor(0.0000)\n",
      "459 tensor(0.0000)\n",
      "460 tensor(0.0000)\n",
      "461 tensor(0.0000)\n",
      "462 tensor(0.0000)\n",
      "463 tensor(0.0000)\n",
      "464 tensor(0.0000)\n",
      "465 tensor(0.0000)\n",
      "466 tensor(0.0000)\n",
      "467 tensor(0.0000)\n",
      "468 tensor(0.0000)\n",
      "469 tensor(0.0000)\n",
      "470 tensor(0.0000)\n",
      "471 tensor(0.0000)\n",
      "472 tensor(0.0000)\n",
      "473 tensor(0.0000)\n",
      "474 tensor(0.0000)\n",
      "475 tensor(0.0000)\n",
      "476 tensor(0.0000)\n",
      "477 tensor(0.0000)\n",
      "478 tensor(0.0000)\n",
      "479 tensor(0.0000)\n",
      "480 tensor(0.0000)\n",
      "481 tensor(0.0000)\n",
      "482 tensor(0.0000)\n",
      "483 tensor(0.0000)\n",
      "484 tensor(0.0000)\n",
      "485 tensor(0.0000)\n",
      "486 tensor(0.0000)\n",
      "487 tensor(0.0000)\n",
      "488 tensor(0.0000)\n",
      "489 tensor(0.0000)\n",
      "490 tensor(0.0000)\n",
      "491 tensor(0.0000)\n",
      "492 tensor(0.0000)\n",
      "493 tensor(0.0000)\n",
      "494 tensor(0.0000)\n",
      "495 tensor(0.0000)\n",
      "496 tensor(0.0000)\n",
      "497 tensor(0.0000)\n",
      "498 tensor(0.0000)\n",
      "499 tensor(0.0000)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access data\n",
    "\n",
    "We can access the raw data of a variable with _data_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-105.4056,   61.2772, -125.2646], grad_fn=<MulBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 100:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward (non-scalar output)\n",
    "\n",
    "_out_ below is a scalar and we do not need to specify any parameters for _backward_. By default, we backpropagate a gradient of 1.0 back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.8823, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out = x.mean()\n",
    "out.backward()    # Same as out.backward(torch.FloatTensor([1.0]))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y$ below is a Tensor of size 3. _backward_ requires a Tensor to specify each backpropagation gradient if the variable is not a scalar. To match each element of $y$, $gradients$ needs to match the size of _y_. In some situtation, the gradient values are computed from the model predictions and the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.4000, 64.0000,  0.0064])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "tensor([[-0.0260,  0.4203,  0.5215],\n",
      "        [-0.0015,  0.3561,  0.1838]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([ 0.0210, -0.0012], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create tensors of shape (10, 3) and (10, 2).\n",
    "x = torch.randn(10, 3)\n",
    "y = torch.randn(10, 2)\n",
    "\n",
    "# Build a fully connected layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1.267463207244873\n"
     ]
    }
   ],
   "source": [
    "# Build loss function and optimizer.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# Forward pass.\n",
    "pred = linear(x)\n",
    "\n",
    "# Compute loss.\n",
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw:  tensor([[ 0.1509,  0.5630, -0.0100],\n",
      "        [ 0.0341,  0.1880, -0.3291]])\n",
      "dL/db:  tensor([ 0.1463, -0.2725])\n"
     ]
    }
   ],
   "source": [
    "# Backward pass.\n",
    "loss.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print ('dL/dw: ', linear.weight.grad) \n",
    "print ('dL/db: ', linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-step gradient descent.\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization:  1.2616931200027466\n"
     ]
    }
   ],
   "source": [
    "# Print out the loss after 1-step gradient descent.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforms\n",
    "\n",
    "> We compose a sequence of transformation to pre-process the image:\n",
    " _Compose_ creates a series of transformation to prepare the dataset. Torchvision reads datasets into PILImage (Python imaging format). _ToTensor_ converts the PIL Image from range \\[0, 255\\] to a FloatTensor of shape (C x H x W) with range \\[0.0, 1.0\\]. We then renormalize the input to \\[-1, 1\\] based on the following formula with $\\mu=\\text{standard deviation}=0.5$.\n",
    "\n",
    "$$\n",
    "input = \\frac{input - \\mu}{\\text{standard deviation}} \\\\\n",
    "input = \\frac{input - 0.5}{0.5}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print(image.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Actual usage of the data loader is as below.\n",
    "for images, labels in train_loader:\n",
    "    pass\n",
    "    # Training code should be written here.\n",
    "    # print(images.size(), labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image grid\n",
    "\n",
    "We often want to display a grid of images to show samples for the training or testing images. torchvision.utils.make_grid a grid to be displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "# inputs contains 4 images because batch_size=4 for the dataloaders\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms images\n",
    "\n",
    "Here is another example in applying cropping, image flipping and scaling to pre-process image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advance Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding = 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, stride = 2)\n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1,400)   # Fix bug here x.view(1,-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "Net = LeNet()\n",
    "tot_params = 0\n",
    "for k in Net.parameters():\n",
    "    print(k.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Linear(in_features=400, out_features=120, bias=True)\n",
      "Linear(in_features=120, out_features=84, bias=True)\n",
      "Linear(in_features=84, out_features=10, bias=True)\n",
      "Softmax()\n"
     ]
    }
   ],
   "source": [
    "for child in Net.children():\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what a parameter looks like - \n",
      " Parameter containing:\n",
      "tensor([[[[ 0.0771, -0.0229, -0.0646, -0.1097,  0.0852],\n",
      "          [-0.1471,  0.1741,  0.1820, -0.0065,  0.1308],\n",
      "          [-0.1051,  0.0019,  0.1518,  0.0463, -0.1765],\n",
      "          [-0.0229,  0.0545, -0.1920,  0.0671, -0.0256],\n",
      "          [-0.1228,  0.0484, -0.0432,  0.0382, -0.0107]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1101, -0.0561,  0.0649, -0.0617, -0.0302],\n",
      "          [ 0.1456, -0.1711,  0.0800,  0.0824,  0.1458],\n",
      "          [-0.0453, -0.0483,  0.1292,  0.1148, -0.1253],\n",
      "          [-0.0077, -0.0183,  0.1940,  0.0082, -0.1202],\n",
      "          [ 0.1916,  0.0205,  0.0627,  0.0722, -0.0667]]],\n",
      "\n",
      "\n",
      "        [[[-0.1457, -0.0188, -0.1652, -0.1701, -0.1931],\n",
      "          [ 0.0139,  0.0080, -0.0236,  0.1443,  0.0006],\n",
      "          [-0.1246, -0.1696, -0.1484, -0.1861,  0.1070],\n",
      "          [ 0.0832,  0.1782, -0.1268,  0.0601, -0.1732],\n",
      "          [ 0.0988, -0.1908, -0.1523, -0.0203, -0.0877]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0064,  0.0919, -0.1561, -0.0387, -0.1095],\n",
      "          [ 0.0612,  0.1864, -0.1048, -0.1426,  0.0083],\n",
      "          [ 0.1651, -0.1586,  0.1907,  0.1579, -0.1325],\n",
      "          [-0.0929,  0.1004,  0.0498,  0.0890,  0.0216],\n",
      "          [ 0.1921,  0.0460,  0.0958, -0.0028,  0.1128]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0490,  0.1826,  0.0213,  0.0832, -0.1042],\n",
      "          [-0.1446, -0.0882,  0.1267, -0.1513, -0.1077],\n",
      "          [ 0.1160, -0.1949,  0.1224, -0.0652,  0.1438],\n",
      "          [ 0.1949,  0.0491, -0.0382,  0.1941,  0.1804],\n",
      "          [ 0.0597, -0.1369,  0.1379,  0.0982,  0.0036]]],\n",
      "\n",
      "\n",
      "        [[[-0.0470, -0.0649,  0.1033, -0.0265, -0.0401],\n",
      "          [-0.1879, -0.1481,  0.0168,  0.0934, -0.0128],\n",
      "          [ 0.0121,  0.0524,  0.1004, -0.0488,  0.1611],\n",
      "          [-0.1997, -0.0536, -0.1905, -0.0246, -0.1099],\n",
      "          [ 0.0022,  0.1785,  0.0209,  0.0453,  0.1854]]]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for child in Net.children():\n",
    "    for param in child.parameters():\n",
    "        print(\"This is what a parameter looks like - \\n\",param)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,parameters in Net.named_parameters():\n",
    "    print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom weight init\n",
    "\n",
    "PyTorch layers are initialized by default in their respective reset_parameters() method. For example:\n",
    "\n",
    "- nn.Linear\n",
    "weight and bias: uniform distribution [-limit, +limit] where limit is 1. / sqrt(fan_in) and fan_in is the number of input units in the weight tensor.\n",
    "- nn.Conv2D\n",
    "weight and bias: uniform distribution [-limit, +limit] where limit is 1. / sqrt(fan_in) and fan_in is the number of input units in the weight tensor.\n",
    "With this implementation, the variance of the layer outputs is equal to Var(W) = 1 / 3 * sqrt(fan_in) which isn't the best initialization strategy out there.\n",
    "\n",
    "Note that PyTorch provides convenience functions for some of the initializations. The input and output shapes are computed using the method _calculate_fan_in_and_fan_out() and a gain() method scales the standard deviation to suit a particular activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(5, 10, (3, 3))\n",
    "        init.xavier_uniform_(self.conv1.weight, gain=np.sqrt(2))\n",
    "        init.constant_(self.conv1.bias, 0.1)\n",
    "\n",
    "network = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Regularization\n",
    "\n",
    "#### L2 Regularization\n",
    "Heavily penalizes peaky weight vectors and encourages diffuse weight vectors. Has the appealing property of encouraging the network to use all of its inputs a little rather that some of its inputs a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 1e-6\n",
    "l2_loss = Variable(torch.FloatTensor(1), requires_grad=True)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'bias' not in name:\n",
    "        l2_loss = l2_loss + (0.5 * reg * torch.sum(torch.pow(W, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 Regularization\n",
    "Encourages sparsity, meaning we encourage the network to select the most useful inputs/features rather than use all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-76d46d2f8d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml1_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'bias'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ml1_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml1_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Variable' is not defined"
     ]
    }
   ],
   "source": [
    "reg = 1e-6\n",
    "l1_loss = Variable(torch.FloatTensor(1), requires_grad=True)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'bias' not in name:\n",
    "        l1_loss = l1_loss + (reg * torch.sum(torch.abs(W)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[[0., 0., 1., 0., 0., 0., 0.]]])\n",
    "k = torch.tensor([[[1., 2., 3.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 2., 1., 0., 0.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.conv1d(x, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 1., 2., 3., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.conv_transpose1d(x, k)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "051f8ed7f0c93aa1aa30fb278ee333bc108b14f52b0c39d794e507a7c646268f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('dl': virtualenvwrapper)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}