{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"case-study-lenet\">Case Study: LeNet</h3>\n",
    "\n",
    "<p>Let’s put everything we’ve learnt together and analyze one of the very early successes<span id=\"lenet\" class=\"margin-toggle sidenote-number\"></span><span class=\"sidenote\">LeNet is published in 1998! CNNs are not exactly new.</span> of convolutional networks: LeNet. This is the <em>architecture</em> of LeNet:</p>\n",
    "\n",
    "<p><span class=\"marginnote\">\n",
    "    <strong>Figure</strong>: LeNet architecture\n",
    "    <a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\">Source</a>.\n",
    "</span>\n",
    "<img src=\"../../images/lenet.png\" />\n",
    "\n",
    "<p>Let’s go over each of the component layers of LeNet:\n",
    "<span id=\"lenet\" class=\"margin-toggle sidenote-number\"></span>\n",
    "<span class=\"sidenote\">\n",
    "    I actually describe slightly modified version of LeNet. \n",
    "</span></p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Input</strong>: Gray scale image of size 32 x 32.</li>\n",
    "  <li><strong>C1</strong>: Convolutional layer of 6 feature maps, kernel size (5, 5) and stride 1. Output size therefore is 6 X 28 x 28. Number of trainable parameters is $(5*5 + 1) * 6 = 156$.</li>\n",
    "  <li><strong>S2</strong>: Pooling/subsampling layer with kernel size (2, 2) and stride 2. Output size is 6 x 14 x 14. Number of trainable parameters = 0.</li>\n",
    "  <li><strong>C3</strong>: Convolutional layer of 16 feature maps. Each feature map is connected to all the 6 feature maps from the previous layer. Kernel size and stride are same as before. Output size is 16 x 10 x 10. Number of trainable parameters is $(6 * 5 * 5 + 1) * 16 = 2416$.</li>\n",
    "  <li><strong>S4</strong>: Pooling layer with same <em>hyperparameters</em> as above. Output size = 16 x 5 x 5.</li>\n",
    "  <li><strong>C5</strong>: Convolutional layer of 120 feature maps and kernel size (5, 5). This amounts to <em>full connection</em> with outputs of previous layer. Number of parameters are $(16 * 5 * 5 + 1)*120 = 48120$.</li>\n",
    "  <li><strong>F6</strong>: <em>Fully connected layer</em> of 84 units. i.e, All units in this layer are connected to previous layer’s outputs<span id=\"fc\" class=\"margin-toggle sidenote-number\"></span><span class=\"sidenote\">This is same as layers in MLP we’ve seen before.</span>. Number of parameters is $(120 + 1)*84 = 10164$</li>\n",
    "  <li><strong>Output</strong>: Fully connected layer of 10 units with softmax activation<span id=\"out\" class=\"margin-toggle sidenote-number\"></span><span class=\"sidenote\">Ignore ‘Gaussian connections’. It is for a older loss function no longer in use.</span>.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Dataset used was MNIST. It has 60,000 training images and 10,000 testing examples.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "import visdom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  0.4.1\n",
      "Torchvision Version:  0.2.1\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_out(W, K, S, P):\n",
    "    return (W - K + 2 * P) / (S) + 1\n",
    "\n",
    "def poll_out(W, K, S):\n",
    "    return np.floor((W - K) / (S)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = conv_out(32, 5, 1, 0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = poll_out(out, 2, 2)\n",
    "out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = conv_out(14, 5, 1, 0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = poll_out(out, 2, 2)\n",
    "out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.convnet = nn.Sequential(\n",
    "                nn.Conv2d(1, 6, kernel_size=5), \n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(6, 16, kernel_size=5),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 120, kernel_size=5),\n",
    "                nn.ReLU())\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(120, 84),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(84, 10), nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.convnet(img)\n",
    "        output = output.view(-1, 120)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = visdom.Visdom()\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', train=True, transform=transforms.Compose([\n",
    "                       transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor()]), \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor()]))\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 1, Batch: 0, Loss: 2.296790\n",
      "Train - Epoch 1, Batch: 10, Loss: 1.978823\n",
      "Train - Epoch 1, Batch: 20, Loss: 0.880726\n",
      "Train - Epoch 1, Batch: 30, Loss: 0.727522\n",
      "Train - Epoch 1, Batch: 40, Loss: 0.525052\n",
      "Train - Epoch 1, Batch: 50, Loss: 0.490573\n",
      "Train - Epoch 1, Batch: 60, Loss: 0.320637\n",
      "Train - Epoch 1, Batch: 70, Loss: 0.273253\n",
      "Train - Epoch 1, Batch: 80, Loss: 0.251605\n",
      "Train - Epoch 1, Batch: 90, Loss: 0.254625\n",
      "Train - Epoch 1, Batch: 100, Loss: 0.239103\n",
      "Train - Epoch 1, Batch: 110, Loss: 0.311514\n",
      "Train - Epoch 1, Batch: 120, Loss: 0.326570\n",
      "Train - Epoch 1, Batch: 130, Loss: 0.209927\n",
      "Train - Epoch 1, Batch: 140, Loss: 0.217677\n",
      "Train - Epoch 1, Batch: 150, Loss: 0.110118\n",
      "Train - Epoch 1, Batch: 160, Loss: 0.184218\n",
      "Train - Epoch 1, Batch: 170, Loss: 0.158139\n",
      "Train - Epoch 1, Batch: 180, Loss: 0.111515\n",
      "Train - Epoch 1, Batch: 190, Loss: 0.076582\n",
      "Train - Epoch 1, Batch: 200, Loss: 0.417697\n",
      "Train - Epoch 1, Batch: 210, Loss: 0.183179\n",
      "Train - Epoch 1, Batch: 220, Loss: 0.200185\n",
      "Train - Epoch 1, Batch: 230, Loss: 0.333344\n",
      "Train - Epoch 1, Batch: 240, Loss: 0.268592\n",
      "Train - Epoch 1, Batch: 250, Loss: 0.324995\n",
      "Train - Epoch 1, Batch: 260, Loss: 0.166743\n",
      "Train - Epoch 1, Batch: 270, Loss: 0.148539\n",
      "Train - Epoch 1, Batch: 280, Loss: 0.094196\n",
      "Train - Epoch 1, Batch: 290, Loss: 0.082655\n",
      "Train - Epoch 1, Batch: 300, Loss: 0.147092\n",
      "Train - Epoch 1, Batch: 310, Loss: 0.080921\n",
      "Train - Epoch 1, Batch: 320, Loss: 0.114795\n",
      "Train - Epoch 1, Batch: 330, Loss: 0.113421\n",
      "Train - Epoch 1, Batch: 340, Loss: 0.052704\n",
      "Train - Epoch 1, Batch: 350, Loss: 0.151228\n",
      "Train - Epoch 1, Batch: 360, Loss: 0.128416\n",
      "Train - Epoch 1, Batch: 370, Loss: 0.227323\n",
      "Train - Epoch 1, Batch: 380, Loss: 0.117883\n",
      "Train - Epoch 1, Batch: 390, Loss: 0.097368\n",
      "Train - Epoch 1, Batch: 400, Loss: 0.131589\n",
      "Train - Epoch 1, Batch: 410, Loss: 0.067981\n",
      "Train - Epoch 1, Batch: 420, Loss: 0.172330\n",
      "Train - Epoch 1, Batch: 430, Loss: 0.030920\n",
      "Train - Epoch 1, Batch: 440, Loss: 0.060127\n",
      "Train - Epoch 1, Batch: 450, Loss: 0.040791\n",
      "Train - Epoch 1, Batch: 460, Loss: 0.112443\n",
      "Train - Epoch 1, Batch: 470, Loss: 0.105905\n",
      "Train - Epoch 1, Batch: 480, Loss: 0.159240\n",
      "Train - Epoch 1, Batch: 490, Loss: 0.078107\n",
      "Train - Epoch 1, Batch: 500, Loss: 0.164418\n",
      "Train - Epoch 1, Batch: 510, Loss: 0.098494\n",
      "Train - Epoch 1, Batch: 520, Loss: 0.083163\n",
      "Train - Epoch 1, Batch: 530, Loss: 0.089693\n",
      "Train - Epoch 1, Batch: 540, Loss: 0.048455\n",
      "Train - Epoch 1, Batch: 550, Loss: 0.057808\n",
      "Train - Epoch 1, Batch: 560, Loss: 0.134646\n",
      "Train - Epoch 1, Batch: 570, Loss: 0.059247\n",
      "Train - Epoch 1, Batch: 580, Loss: 0.183834\n",
      "Train - Epoch 1, Batch: 590, Loss: 0.139720\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-9dfc66c4aae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-9dfc66c4aae0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-9dfc66c4aae0>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-9dfc66c4aae0>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtotal_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Avg. Loss: %f, Accuracy: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_correct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_test' is not defined"
     ]
    }
   ],
   "source": [
    "net = LeNet5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=2e-3)\n",
    "\n",
    "cur_batch_win = None\n",
    "cur_batch_win_opts = {\n",
    "    'title': 'Epoch Loss Trace',\n",
    "    'xlabel': 'Batch Number',\n",
    "    'ylabel': 'Loss',\n",
    "    'width': 600,\n",
    "    'height': 400,\n",
    "}\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global cur_batch_win\n",
    "    net.train()\n",
    "    loss_list, batch_list = [], []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = Variable(images), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(images)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        batch_list.append(i+1)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.item()))\n",
    "\n",
    "        # Update Visualization\n",
    "        if viz.check_connection():\n",
    "            cur_batch_win = viz.line(torch.FloatTensor(loss_list), torch.FloatTensor(batch_list),\n",
    "                                     win=cur_batch_win, name='current_batch_loss',\n",
    "                                     update=(None if cur_batch_win is None else 'replace'),\n",
    "                                     opts=cur_batch_win_opts)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test():\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = Variable(images), Variable(labels)\n",
    "        output = net(images)\n",
    "        avg_loss += criterion(output, labels).sum()\n",
    "        pred = output.data.max(1)[1]\n",
    "        total_correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "\n",
    "    avg_loss /= len(data_test)\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.data[0], float(total_correct) / len(test_loader)))\n",
    "\n",
    "\n",
    "def train_and_test(epoch):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "\n",
    "def main():\n",
    "    for e in range(1, 16):\n",
    "        train_and_test(e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
