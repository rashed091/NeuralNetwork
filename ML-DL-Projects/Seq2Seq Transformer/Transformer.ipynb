{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Transformer: French to English\n",
    "\n",
    "Karl Heyer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was motivated by [fast.ai Lesson 11](http://course.fast.ai/lessons/lesson11.html) and a desire to understand the Transformer from [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf). fast.ai lesson 11 builds a seq2seq transformer for French to English translation using an LSTM based encoder/decoder model initialized with pretrained word vectors. I wanted to apply the same use of pretrained word vectors to a Transformer and expand the dataset used to train the model.\n",
    "\n",
    "The data used comes from a [corpus](http://www.statmt.org/wmt15/translation-task.html) created by Chris Callison-Burch. The dataset was created by crawling english and french versions of web sites to create a parallel corpus. We will use the first 2 million sentence pairs from the dataset to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/translate')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname='giga-fren.release2.fixed'\n",
    "en_fname = PATH/f'{fname}.en'\n",
    "fr_fname = PATH/f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = pickle.load((PATH/'fr-en-all.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = qs[:2000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_qs,fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input text will be tokenized with spaCy tokenizers for English and French. For memory reasons we will only keep sentence pairs where the English sentence has less than 50 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.array([len(o)<50 for o in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1826350"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(en_tok, (PATH/'en_tok_all.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok_all.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok_all.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok_all.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(50000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids_all.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos_all.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids_all.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos_all.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = load_ids('en')\n",
    "fr_ids,fr_itos,fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 98))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 97))\n",
    "enlen_90,frlen_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids_tr = np.array([o[:enlen_90] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:frlen_90] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1643912, 182438)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr))>0.1\n",
    "en_trn,fr_trn = en_ids_tr[trn_keep],fr_ids_tr[trn_keep]\n",
    "en_val,fr_val = en_ids_tr[~trn_keep],fr_ids_tr[~trn_keep]\n",
    "len(en_trn),len(en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = Seq2SeqDataset(fr_trn,en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val,en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(43, 23), (56, 38), (47, 23), (51, 32), (31, 15)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the Transformer model, in all it's glory. The code used here was taken from [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html) by Alexander Rush and [How to Code the Transformer in PyTorch](https://blog.floydhub.com/the-transformer-in-pytorch/) by Samuel Lynn-Evans.\n",
    "\n",
    "The first module is a simple embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Transformer, having moved away from sequential models, needs a way understand where words are in a sentence. This is done through a positional encoder. The encoder models sentence position and length as a sine function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 80):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:,:seq_len], \\\n",
    "        requires_grad=False).cuda()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic attention calculation, given by the following equation:\n",
    "\n",
    "$$                                                                         \n",
    "   \\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V               \n",
    "$$      \n",
    "\n",
    "Where Q, K and V stand for Query, Key and Value. In the encoder layers of the Transformer, Q, K and V all come from the encoder output of the previous layer, performing self-attention over the input sentence. In the decoder layers of the Transformer, the Query is the hidden state being decoded, while the Key and Value values come from the encoder. This means that every layer in the decoder performs attention on the final encoder output that represente the input sequence.\n",
    "\n",
    "The attention function also incorporates masking into the attention function. Masking is an important concept in the Transformer. It controls what the model can see and when. For the input sequence, the mask used is a vector that contains 0s wherever the input sentence is padded. In the target sentence, the mask is a two dimensional matrix that masks over the entire target sentence one word at a time. The first row of the target mask masks every word but the first. The second row masks everything except the first two words. And so on until the final row that allows the model to see the entire sequence. This mimics forcing the model to look at one word at a time.\n",
    "\n",
    "It is important to note though this occurrs entirely within the attention function and at the end of the model, only a single output prediction will be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things get a bit weird here. Before actually calculating attention over Q, K and V values, the input values are put through linear layers and broken into a several heads. Each head of the input is attended to separately, allowing the model to perform attention on many different representations of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "                \n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # transpose to get dimensions bs * h * sl * d_model\n",
    "       \n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a standard feed forward network that will be used in the encoder and decoder layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout = 0.2):\n",
    "        super().__init__() \n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer outputs are normalized before being passed to the next layer. The parameters $\\alpha$ and $bias$ used in the calculation are learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.size = d_model\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the individual layers of the encoder and the decoder. The encoder layer has one attention layer before a feed forward layer. Notice the inputs to the encoder attention are all the same thing.\n",
    "\n",
    "The decoder layer has two attention layers before a feed forward layer. Notice the input to the first attention layer is the target sentence and the target mask. The input to the second attention layer includes the outputs from the encoder layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model).cuda()\n",
    "        \n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the main Encoder and Decoder classes that will contain multiple encoder layers and decoder layers.\n",
    "\n",
    "The setup of the decoder layer does somewhat bug me. The initial input to the Decoder, `trg`, is the output sentence the model is supposed to be predicting. On a certain level this just doesn't feel right to me. Will the model just learn to reproduce the target input? As I understand it, the masking of the output sentence is supposed to prevent the model from 'cheating', but it still seems odd to train your model with the output you expect.\n",
    "\n",
    "In practice, I haven't seen an obvious difference in translation quality between predictions made by the model with target inputs and without. The people who came up with the model are way better at this stuff than I am, so I'll trust their design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we put everything together - the Encoder, the Decoder, and the final feed forward layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for generating masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nopeak_mask(size):\n",
    "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
    "    np_mask =  Variable(torch.from_numpy(np_mask) == 0).cuda()\n",
    "\n",
    "    return np_mask\n",
    "\n",
    "def create_masks(src, trg):\n",
    "    \n",
    "    src_mask = (src != 1).unsqueeze(-2)\n",
    "\n",
    "    if trg is not None:\n",
    "        trg_mask = (trg != 1).unsqueeze(-2)\n",
    "        size = trg.size(1) # get seq_len for matrix\n",
    "        np_mask = nopeak_mask(size).cuda()\n",
    "\n",
    "        trg_mask = trg_mask & np_mask\n",
    "        \n",
    "    else:\n",
    "        trg_mask = None\n",
    "        \n",
    "    return src_mask, trg_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function used for this model is standard cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model requires four inputs - the source sentence, the source mask, the target sentence and the target mask. The easiest way to plug this into a fast.ai framework is to use a custom stepper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformStepper(Stepper):\n",
    "    def step(self, xs, y, epoch):\n",
    "        xtra = []\n",
    "        \n",
    "        src = V(xs[0].transpose(0, 1))\n",
    "        trg = V(y.transpose(0, 1))\n",
    "        \n",
    "        trg_input = trg[:, :-1]\n",
    "        targets = trg[:, 1:].contiguous()\n",
    "        \n",
    "        src_mask, trg_mask = create_masks(src, trg_input)\n",
    "        \n",
    "        output = self.m(src, trg_input, src_mask, trg_mask)\n",
    "        \n",
    "        \n",
    "        if isinstance(output,tuple):\n",
    "            output,*xtra = output\n",
    "            \n",
    "        self.opt.zero_grad()\n",
    "        loss = raw_loss = self.crit(output, targets)\n",
    "        \n",
    "        if self.reg_fn:\n",
    "            loss = self.reg_fn(output, xtra, raw_loss)\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        if self.clip:  \n",
    "            nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "            \n",
    "        self.opt.step()\n",
    "        \n",
    "        return raw_loss.data\n",
    "    \n",
    "    def evaluate(self, xs, y):\n",
    "        src = V(xs[0].transpose(0, 1))\n",
    "        trg = V(y.transpose(0, 1))\n",
    "        \n",
    "        trg_input = trg[:, :-1]\n",
    "        targets = trg[:, 1:].contiguous()\n",
    "        \n",
    "        src_mask, trg_mask = create_masks(src, trg_input)\n",
    "        \n",
    "        preds = self.m(src, trg_input, src_mask, trg_mask)\n",
    "\n",
    "        if isinstance(preds,tuple): preds=preds[0]\n",
    "        return preds, self.crit(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "\n",
    "Here we create the model. We will use a `d_model` value of 300, as that corresponds to the fastText word vectors we will be using later. Experimentally I found using `heads = 10` performed better than 6 (with 7, 8 and 9 being unusable as d_model/heads must be an integer value). An encoder and decoder depth of `N = 6` was used by the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 300\n",
    "heads = 10\n",
    "N = 6\n",
    "\n",
    "src_vocab = len(fr_itos)\n",
    "trg_vocab = len(en_itos)\n",
    "model = to_gpu(Transformer(src_vocab, trg_vocab, d_model, N, heads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model with a xavier uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up our learner and away we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.9, 0.98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, SingleModel(to_gpu(model)), opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca38f09a78e4c9a980982ff9988ff2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████▊                  | 5101/9538 [09:08<07:56,  9.30it/s, loss=tensor(18.2513, device='cuda:0')]"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd81eXZx/HPRSAsww57CzIEAQ3iLipVBKt1a5W6qbaPWlv7iKPV1joetbZaHweKVZ+qtY46cSsulgFBlih7CWGvkISccz1/nEMIIQlJyJm/7/v1yivn/Ma5r9wcznXu3+8e5u6IiEhw1Ul0ACIiklhKBCIiAadEICIScEoEIiIBp0QgIhJwSgQiIgGnRCAiEnBKBCIiAadEICIScEoEIiIBVzfRAVRFq1atvGvXrokOQ0QkpUybNm2du2fv67iUSARdu3YlNzc30WGIiKQUM1taleN0aUhEJOCUCEREAk6JQEQk4JQIREQCTolARCTglAhERAJOiUBEJAltyi/i/TmrWbetMOZlKRGIiCShhWu3M/r/pjFn1ZaYl6VEICKShEJhB6BuHYt5WUoEIiJJqDgcBiBDiUBEJJjUIhARCbjiaCJQi0BEJKBCoV0tgth/TCsRiIgkIbUIREQCruQeQYYSgYhIIKnXkIhIwKVFryEze8rM8sxsdpnt15jZfDObY2b3xqp8EZFUli73CJ4GhpfeYGbHA6cDh7j7wcD9MSxfRCRl7W4RpHCvIXf/DNhQZvPVwD3uXhg9Ji9W5YuIpLJ0aRGU5yDgWDObYmafmtngOJcvIpISQqHIzeJ43COoG/MS9i6vOXAEMBj4t5l1d3cve6CZjQZGA3Tu3DmuQYqIJFpJiyANu4+uAF71iKlAGGhV3oHuPtbdc9w9Jzs7O65Biogk2q57BBmWfongNeAEADM7CMgE1sU5BhGRpBfy+N0jiNmlITN7ARgKtDKzFcBtwFPAU9EupUXAxeVdFhIRCbpdn4x14tAiiFkicPcLKth1UazKFBFJF7suDcWhQaCRxSIiySgcx0tDSgQiIkkoHG0RWBreLBYRkSoIe3xaA6BEICKSlELucbk/AEoEIiJJKRz2uPQYAiUCEZGkFHYlAhGRQAuFdY9ARCTQwrpHICISbGF36qhFICISXGH3uEw4B0oEIiJJKRSOz2AyUCIQEUlK7k5GnD6hlQhERJJQSOMIRESCLezxmYIalAhERJJSpNdQfMpSIhARSULqNSQiEnC6RyAiEnDuaECZiEiQRVoE8SlLiUBEJAlp9lERkYBTIhARCbhQ2DUNtYhIkEUGlMWnrJglAjN7yszyzGx2OftuMDM3s1axKl9EJJWlyzTUTwPDy240s07Aj4FlMSxbRCSlpcWAMnf/DNhQzq6/Av8NeKzKFhFJdWk7oMzMTgNWuvvMeJYrIpJqwk7c5hqqG59iwMwaAbcAJ1Xx+NHAaIDOnTvHMDIRkeQTDjt168YnE8SzRXAg0A2YaWZLgI7AdDNrW97B7j7W3XPcPSc7OzuOYYqIJF7Y49d9NG4tAnefBbTe9TyaDHLcfV28YhARSRUhT4OlKs3sBWAS0MvMVpjZ5bEqS0Qk3bg7GXEaRxCzFoG7X7CP/V1jVbaISKpL215DIiJSNWFNQy0iEmxhTUMtIhJs8ew1pEQgIpKEQu6p32tIRERqzp3Un2tIRERqTktViogEXCicHtNQi4hIDbmWqhQRCbZQOqxHICIiNacBZSIiAacBZSIiAacBZSIiAadJ50REAs4dJQIRkSALue4RiIgEmu4RiIgEXDicBktViohIzUVaBPEpS4lARCQJhTTFhIhIcLm7eg2JiARZ2CO/lQhERAIq7JFMoHsEIiIBFYo2CVK+15CZPWVmeWY2u9S2+8zsWzP7xsz+Y2bNYlW+iEiq2t0iSPFEADwNDC+z7QOgn7sfAnwH3BTD8kVEUtLuewTxKS9micDdPwM2lNn2vrsXR59OBjrGqnwRkVS169JQEG4WXwa8k8DyRUSSkqfRpaEKmdktQDHwXCXHjDazXDPLXbt2bfyCExFJsLRvEZjZxcCpwIW+K+2Vw93HunuOu+dkZ2fHL0ARkQQruUcQpxZB3biUEmVmw4EbgR+5e348yxYRSRW7eg2l/M1iM3sBmAT0MrMVZnY58DCQBXxgZjPM7LFYlS8ikqpKuo/G6dJQzFoE7n5BOZvHxao8EZF0kfb3CEREpHIe53sESgQiIklmd4sgPuUpEYiIJJl0mmJCRERqYFciSPlJ50REpGZ2jSOIV68hJQIRkSSjewQiIgFXMqBM9whERIIpHI781jgCEZGACiXjUpVmdp2ZNbGIcWY23cxOinVwIiJBtHuuoeRqEVzm7luAk4Bs4FLgnphFJSISYOEknWJiVzQjgH+4+8xS20REpBaVdB9NspvF08zsfSKJ4D0zywLCsQtLRCS4dnUfjVODoMqzj14ODAQWuXu+mbUgcnlIRERqmcd5GuqqtgiOBOa7+yYzuwi4Fdgcu7BERIIrlKTjCB4F8s1sAPDfwFLg2ZhFJSISYCVLVSZZi6A4ur7w6cCD7v4gkZXGRESkloWTdIqJrWZ2EzAKeNvMMoB6sQurdoyf9QO3vjar5HqbiEgqSNZpqM8DComMJ1gNdADui1lUtWRh3jb+OXkZr81YmehQRESqLCmXqox++D8HNDWzU4ECd0/6ewS/PL4HOV2ac/sbc1m5aUeiwxERqZKkvEdgZucCU4FzgHOBKWZ2diwDqw0ZdYx7zupP2J0Ln5jM4nXbEx2SiMg+7Z59ND7lVbWYW4DB7n6xu/8cOBz4fezCqj09Wmfx9KWD2bxjJ+c+PokFedsSHZKISKXCSTqOoI6755V6vr4a5ybcYV1a8OIvjsTdOeexiXy/ZmuiQxIRqdDukcXJlQjeNbP3zOwSM7sEeBsYX9kJZvaUmeWZ2exS21qY2Qdm9n30d/Oah149B7XJ4uWrjqJuRh1GjZvKio358SpaRKRaPBnnGnL33wFjgUOAAcBYd79xH6c9DQwvs20M8JG79wQ+ij6Pm66tGvPsZYeTX1TMqHFTydtSEM/iRUSqJGmXqnT3V9z9N+5+vbv/pwrHfwZsKLP5dOCZ6ONngJ9WOdJa0qddE566ZDBrthRw9mOTWL1ZyUBEkksomdYjMLOtZralnJ+tZralBuW1cfcfAKK/W9ck6P2V07UFz195BBu2F3Hhk5NZt60wEWGIiJTLk2lAmbtnuXuTcn6y3L1JLAMzs9FmlmtmuWvXrq311x/YqRnjLs5hxcYdXPvC1+wMaVZtEUkOoTRfs3iNmbUDiP7Oq+hAdx/r7jnunpOdnR2TYIZ0b8mdZ/Rn4sL13PIfTUUhIskhWccR1JY3gIujjy8GXo9z+Xs5+7COXHtCD/6du4IXv1qe6HBERJJ2zeJqM7MXgElALzNbYWaXE1nn+Mdm9j3wY5Jk3eNfDzuIo3u05A9vzGH2Si2zICKJtWv20WQbUFZt7n6Bu7dz93ru3tHdx7n7enc/0d17Rn+X7VWUEHXqGA+eP4iWjTO5+rlpbCssTnRIIhJgoWScaygIWh1Qn7+eN5BVmwq45vnpFOvmsYgkiKf5PYKkdkT3ltxxej8+mb+WP789L9HhiEhAJeU01EHysyGdueSorjw9cQlTFq1PdDgiEkDhZJxiImhuHN6b9k0bcMfbcykq1iUiEYmvXb2G4tQgUCIoT8PMDH5/al9mr9zCXeN1iUhE4itteg2lulP6t+Oyo7vx9MQlvP3ND4kOR0QCJKnmGgq6Maf0ZlDnZox59RuWaHUzEYmTkqUqdY8g8TLr1uGh8wdRx4wbXppZcidfRCSWwmGP2xTUoESwT51aNOIPp/Yld+lGHvt0YaLDEZEACLnHrccQKBFUyZmHduAnA9rzwAffMW3pxkSHIyJpLuwet2UqQYmgSsyMO8/oR7umDbj2ha/ZvGNnokMSkTQWDjt11SJIPk0a1OOhCwaxavMOHpmwINHhiEgaKw573LqOghJBtRzauTlnDOrAU18sZu6qmizQJiKyb+Gwk5GhRJC0fj+yL00bZnLDSzO1qpmIxIRaBEmueeNM7jyjH3N/2MIjn6gXkYjUvlBYvYaS3skHt+X0ge35+8ffM3/11kSHIyJpJqSbxanhtp8cTFaDuvz2pRlau0BEalUo7HEbVQxKBDXWonEmf/5pf2av3MLTE5ckOhwRSSMhV4sgZYzo35bje2XzwAffsXxDfqLDEZE0UawWQeowM+74aT/qmPH712eXLC8nIrI/NKAsxXRs3ohfD+vJhPlrmfDd2kSHIyJpoDjscZuCGpQIasXFR3WldVZ9HpuwUK0CEdlvobBTVwPKUku9jDr81wk9mLJ4AxMXap1jEdk/kXEE8ft4ViKoJWcf1pG2TRpw1/h5WrdARPZLKOzEsUGQmERgZteb2Rwzm21mL5hZg0TEUZsaZdbl1lP7MGfVFp5Rd1IR2Q+RAWVp3CIwsw7AtUCOu/cDMoDz4x1HLIzs346hvbK5//355G0tSHQ4IpKiIgPK4ldeoi4N1QUamlldoBGwKkFx1Coz49aRfckvCvHoBM1DJCI1ExlQlsYtAndfCdwPLAN+ADa7+/tljzOz0WaWa2a5a9emTrfMHq0P4PzBnXhm4hINMhORGkn7AWVm1hw4HegGtAcam9lFZY9z97HunuPuOdnZ2fEOc79cN6wn9etmcNsbc9SdVESqLQgDyoYBi919rbvvBF4FjkpAHDHTrmlDbji5Fx9/m8dL01YkOhwRSTHFAZiGehlwhJk1ssjqzCcC8xIQR0xdelRXhnRrwR/fmMOCvG2JDkdEUkgoHE7vhWncfQrwMjAdmBWNYWy844i1OnWMv50/kPr1MvjtSzMJa2yBiFRRKAhLVbr7be7e2937ufsody9MRByx1q5pQ24d2YeZyzfxYu7yRIcjIikipKUq08sZgzowpFsL7nnnW9ZtS8t8JyK1TOsRpBkz484z+pFfVMzd479NdDgikgJCoTTvPhpEPVpncfkx3Xll+gqWrt+e6HBEJMmpRZCmfnZ4ZwCe+mJxgiMRkWQXCkD30UDq3LIRFx3RmWcmLWXa0o2JDkdEklgQxhEE1g0n9aJZo3r89t8z2F5YnOhwRCRJqUWQxpo1yuSv5w5kyfp8Xpi6LNHhiEiSUvfRNDe0VzaHR7uTfjh3TaLDEZEkFIgBZUFmZoy7OIe+7Zvwy+emM3HhukSHJCJJRi2CAMhqUI9xFw+mS8tGXPqPr5i5fFOiQxKRJKLuowGRnVWf564cQqPMDH71/HQ2bC9KdEgikgTCYccdDSgLitZZDfifsw4hb0shP/n7F3y1ZEOiQxKRBNsZDgOoRRAkJx3clhd/cQShsHPOY5O0qplIwBUVRxJBg3oZcStTiSAJDOrcnMdHHQbA8L99xuYdOxMckYgkSmE0EdSvm8ZrFkv5BnRqxoPnDyR/Z4jTHv6CKYvWJzokEYkzd+f9OZFu5ZlKBMF0+sAO/OWcASxdn895YyezUTeQRQLl3dmrufk/s4BI78J4USJIMmce2pG/XzAIgEF3fMC5j08ipNXNRNLexu1FXP3c9JLn7Zs1jFvZSgRJ6CcD2vPK1UcBMHXxBg65/T0lA5E097cPvyt5/NhFhzKwU7O4la1EkKQO69KceX8aDsD2ohBH3v0RC/K2UVgcSnBkIlLbthUW88ykpQB8c/tJDO/XLq7lKxEksYaZGUy5+UQA8rYWMuyBT+l167sMvvNDlqzbTnEonOAIRaQ2/HzcFABuHN6bJnG8N7BL3biXKNXSpkkDPvzNcXz8bR53RZe6XLu1kKH3TwBg3MU5nNinTQIjFJGqyi8qZuRDX7B43e6VCo/t2YrpyyLTzFx2TNeExGXuyX/tOScnx3NzcxMdRlIo2Bni8U8X8dY3q/g+bxsAj154KKf0j29TUkSq58WvlnHjK7Mq3H/p0V257ScH12qZZjbN3XP2eZwSQep6+svF3P7mXAAW3jUirgtZiMi+LVufz+szVlKnjnHfe/NLtj93xRAaZmZw5iMTAXjg3AGceWjHWi+/qokgIZeGzKwZ8CTQD3DgMneflIhYUtklR3cjb2shj0xYyIE3j+fKY7tx0yl94jpZlYjsrbA4xE2vzuLV6SvL3X/UgS0xM5bcMzLOkZUvIS0CM3sG+NzdnzSzTKCRu1c4F7NaBBULhZ3j7v2ElZt2lGzr264JL/7iiLgOSBERGD/rB35ZaixAaXed0Z+R/duRv7OYdk3jM0YgaS8NmVkTYCbQ3atYuBLBvk1cuI6fPTGl5HmjzAzm/PFkLI6LW4ikqy0FO8mqX7fk/9ODH37PX6P9/s8Y1IGfDenMOY/tfVFj1BFdGNipGf06NKVX26y4xgzJnQgGAmOBucAAYBpwnbtvr+gcJYKq2RkK8/2abYx46POSbfeedQjnDu6UwKhEUo+7Y2a4O3/94Dse+ngBWQ3qsrWgmFtG9OHO8fMqPPeYHq14+GeDaNKgXsIv0yZzIsgBJgNHu/sUM3sQ2OLuvy9z3GhgNEDnzp0PW7p0aVzjTGUL8rYy7IHPSp5/cP1x9GwT/28jIqnG3bnvvfk8MmEh3bMbs2hthd9P+cs5A/jtSzP32Pbdn0+J62Rx+5LMiaAtMNndu0afHwuMcfcK75qoRVB9z09ZVjJ51S7f3jE8rnOciySLbYXF9LvtvT22jTqiC386/WCenbSUztFlYzs0a7jH/baKjL/2WPq2bxKrcGtN0iYCADP7HLjC3eeb2e1AY3f/XUXHKxHUzPbCYg4u8+bPvXUYrQ6oz5otBUxetJ6R/dtRNyN5vsGI1KZ3Z6/mqn9Oq/H5VxzTjdMHdqB/x6ZApDdQ/bqp82Uq2RPBQCLdRzOBRcCl7r6xouOVCPZP3tYCDr/zowr3q9uppBp3J+xUOnbmmxWbOO3hL0ueH9uzFZ9/vw6AYX1a8+G8vHLPe+yiQ+M+10+sJHUiqC4lgv1XXuugrOeuGMLRPVrFKSKRmtlasJNR46YyY/kmWjbOZP32InK6NGdI9xaM7N+evu2bsGrTDo6652Mg0mf/j6cdzIHZB+zxZWfcF4u54625/HLogTRpWI+rfnRgov6kmFEikHItXb+dnSGnR+sDmLtqyx49jAAGdGzKM5cdTrNGmQmKUGRv2wuL+W7NVvp3aEqPW96p9NgJNwwtmYsLdl8ODSIlAqmyt7/5gV89v+cgmN+d3ItthcU8OmEhT/48h2F9NbGdJMbG7UUMuuODCvcf1qU505bufWW5f4emPH/lkEAPrFQikGpZuHYb/85dzuOfLip3/4e/OY4erdUFVWpmzqrNjHzoC24d2Ycrju1e7jGzV27mymdzeee6Y2mYmcG/pi5nxvJN/OfrPadp6NUmi3d/fSwFO8M4TqPMyEw5N7w0k5enrSg5bsGdpwS+I4QSgdTIrBWbOevRiRSVWevgqh8dyJhTegPw4dw1/LClgFFHdElEiJJiPv9+LaPGTS15PuaU3jz5+WLuObM/Vzybixns62Po5hG9S6Zhr+gDvmBniH9OXsqf357H70/ty+XHdKvVvyMVKRFIrXB3ut00Hti7p8WugWrhsHPiA59y4/DeDO/XtmT/yk07mLViEycf3FZTXaSZcNjZkF/Eu7NXc+trs/nkhqF0a9V4r+NKz5C7PxbfPaJkpK/eS1WnRCC1puuYt6t0XLumDRjYqRk7Q86H89aUbO/VJotnLz+cNk0axCpEiZMdRSGGP/gZS9fn77VvyT0j2Zy/k1Me/Iy8rYUUl1pn+4mf5zCsT2uG3PUReVsLy33tm0f05opjutP95vHkdGlOpxaNWLRuO384tQ+HdWkRs78pnSkRSK15dtIS/vD6nJLnX445gePvn0BRcfWWyjxjUAf+et7AWo5OYsndyV26kUGdmvGfr1fyu5e/qfDYXV05y/rqlmFkZ+3utbNq0w7aNmmgcStxoEQgtWrdtkJaNs7co1nu7tz4yjfUzahDo3oZPPnF4pJ9vdpk8fyVQxjz6iw+mLu7dfD8lUOoXzeDQzs32+O1pi/bSN92TTQFRpK57fXZJYuql7borhGs2VpAu6YNeWbiEm57Y045Z8PEMSfQvll8plyWvSkRSFwV7AyxtaCYVgfsmSzKToBX2gm9W3Pv2YeQ8+cPS7adm9ORQzo24yLdiI65stfbpyxaT+7Sjfzq+B5AZHWt4+77ZI9z+rRrwvhrj9njvLVbCxl85+5/w+/vPIV6Ae+tkyyUCCSpFIfC+xwIVJm2TRrw6EWHMqhz8z22T1+2kelLN9I9uzG92jahg759lgiHnSmLN3D1c9N47KLDWLh2G8UhZ9rSjUxatJ61Wwu55Kiu3H7awbw5cxXXvPA1AM9edjiHdmleMknb4d1aMHfVFqbecmJJV83yFBWH2RkK07h+QhY+lHIoEUjSWbY+ny8WrGNE/7Zc/c/pTFq0HoAR/dty4ZAuXPjklErPb3VAfXJvHQbAPe98y2OfLtzrmH9cMpjje7eu/eBTTFFxmINurVrivezobjz15eJy9/32xwdxzYk9azM0iSMlAkl6781ZzfbC4r0W7b7ima9YtiGf5644gqe+XMyjE/b+wC9tYKdmzFi+90qnX445gfZNG2BmvD9nNQM6NQtEz6UFedsY9sCnlR5z+THdWLYhf4/7N2NO6c0973y7x3G7um1KalIikLTy8bdruOzpPd8DM/9wEk0b7Z4+4Nh7P2b5hsrnkn/+yiFMXLCenK7N+WFzAeu2FvLe3NUc2b0lZx7akT7tkn+O+fLkFxVzxv9OZP6arSXbThvQngfPH7jHB/nqzQW0aVK/ZNuursG/OK47N43ow1dLNjBq3BTGDO/NuYM7VXopSJKfEoGknV//62tem7GKRpkZfHPbSXuNLt1RFGLphu0M/9vnFbxC5cxg8d0jCYedacs2ktOledJ8G16ybjuNMjNYuHY7FzwxGYB5fxrOvNVb6N02i75/2HNm2d+d3Kvkpm9l/veTBWzcXsStp/aNSdySWEoEknbCYWfyovUceWDLKn1AL9+Qz7H3fsINJx3E1UN7cODN4/c65uYRvSnYGeZfU5exanMBJ/ZuzUff7h493axRPQ5qk8W9Zx1C1+jI2eJQeL/msAmFnW2Fxdz2+mxem7GKBvXq8MH1P6JTi0Ys35DPK9NX0LRhPX5+ZFdmLN/EWY9OrPJr33/OAM4+rOO+D5RAUCIQKSO/qBh3yu3V8sn8PC79x1fVfs0+7Zrw+q+OLlmn1t0p2BmmQb06PPH5Ip6fsowl5YzC3R+NMzPYXhTaa7uWIpWyqpoIdAFQAqOy690/6pld8viO0w/m0C7NeWPGKuav2cqE+WsrPG/eD1tKeud0admo3KkXKnPdiT158KPvKz3mzEEduO+cAbz29Uoa189geL92vDlzFb9/fTbvX38cD374Pb847kAlAakxtQhEqqA4FGbTjp0U7AzRvmlDthUVk7eloMLBcrucm9ORa07oyej/m8bI/m35rxN6UrAzRL2MOiXLLG7YXsT2wmLe/GYVFx7epeQG+KpNO2gX7fUkUhO6NCQSBxMXrOP7vG0sXZ/PU18uLlnuc0dRiIaZ+oYuiaVEICIScFVNBJoQREQk4JQIREQCTolARCTgEpYIzCzDzL42s7cSFYOIiCS2RXAdMC+B5YuICAlKBGbWERgJPJmI8kVEZLdEtQj+Bvw3UL1Fb0VEpNbFPRGY2alAnrtP28dxo80s18xy166teIi/iIjsn7gPKDOzu4FRQDHQAGgCvOruF1Vyzlqg9AraTYHNFTwvu68VsG7/I99D2TJq65yKjqnO9srqpuzzdKibivYlY91UFNf+Hl/duqloe9D+X1W0L53eO83cPXufR7p7wn6AocBbNThvbEXPy9mXG4O4x8binIqOqc72yuqmnLpK+bqpaj0kQ93UpH5iUTc1qZ90/H+l987un1QdR/BmJc/L7otH+bV1TkXHVGd7ZXVT1Tj2R7zrpqJ9yVg3NSkjFnVT0fag/b+qaF+Q3jtAisw1tD/MLNerMNdGEKluKqa6qZzqp2KpWDep2iKojrGJDiCJqW4qprqpnOqnYilXN2nfIhARkcoFoUUgIiKVUCIQEQk4JQIRkYALbCIws6Fm9rmZPWZmQxMdTzIys8ZmNi06GlyizKxP9H3zspldneh4ko2Z/dTMnjCz183spETHk0zMrLuZjTOzlxMdS2kpmQjM7CkzyzOz2WW2Dzez+Wa2wMzG7ONlHNhGZHTziljFmgi1VD8ANwL/jk2UiVEbdePu89z9KuBcIKW6Ce5LLdXPa+5+JXAJcF4Mw42rWqqbRe5+eWwjrb6U7DVkZscR+RB/1t37RbdlAN8BPybywf4VcAGQAdxd5iUuA9a5e9jM2gAPuPuF8Yo/1mqpfg4hMlS+AZG6Sot1I2qjbtw9z8xOA8YAD7v78/GKP9Zqq36i5/0FeM7dp8cp/Jiq5bp52d3Pjlfs+1I30QHUhLt/ZmZdy2w+HFjg7osAzOxfwOnufjdQ2aWNjUD9WMSZKLVRP2Z2PNAY6AvsMLPx7p7ys8XW1nvH3d8A3jCzt4G0SQS19N4x4B7gnXRJAlDrnztJJSUTQQU6AMtLPV8BDKnoYDM7EzgZaAY8HNvQkkK16sfdbwEws0uItp5iGl1iVfe9MxQ4k8gXiPExjSw5VKt+gGuAYUBTM+vh7o/FMrgEq+57pyVwJzDIzG6KJoyES6dEYOVsq/C6l7u/Crwau3CSTrXqp+QA96drP5SkU933zgRgQqyCSULVrZ+HgIdiF05SqW7drAeuil04NZOSN4srsALoVOp5R2BVgmJJRqqfiqluKqf6qVha1E06JYKvgJ5m1s3MMoHzgTcSHFMyUf1UTHVTOdVPxdKiblIyEZjZC8AkoJeZrTCzy929GPgv4D1gHvBvd5+TyDgTRfVTMdVN5VQ/FUvnuknJ7qMiIlJ7UrJFICIitUeJQEQk4JQIREQCTolARCTglAhERAJOiUBEJOCUCKTWmdm2OJRxWhWn0q7NMoea2VE1OG+QmT0ZfXyJmSXF3FZm1rXslMrlHJNtZu/GKyZJDCUCSVrRKX7L5e5vuPuIW0f2AAAEuUlEQVQ9MSizsvm3hgLVTgTAzcDfaxRQgrn7WuAHMzs60bFI7CgRSEyZ2e/M7Csz+8bM/lhq+2sWWf1sjpmNLrV9m5n9ycymAEea2RIz+6OZTTezWWbWO3pcyTdrM3vazB4ys4lmtsjMzo5ur2Nmj0TLeMvMxu/aVybGCWZ2l5l9ClxnZj8xsylm9rWZfWhmbaLTD18FXG9mM8zs2Oi35Veif99X5X1YmlkWcIi7zyxnXxcz+yhaNx+ZWefo9gPNbHL0Nf9UXgvLIqvHvW1mM81stpmdF90+OFoPM81sqpllRb/5fx6tw+nltWrMLMPM7iv1b/WLUrtfA9JmvQ4ph7vrRz+1+gNsi/4+CRhLZIbGOsBbwHHRfS2ivxsCs4GW0ecOnFvqtZYA10Qf/xJ4Mvr4EiKLwgA8DbwULaMvkfnhAc4mMk10HaAtkbUnzi4n3gnAI6WeN2f3qPsrgL9EH98O3FDquOeBY6KPOwPzynnt44FXSj0vHfebwMXRx5cBr0UfvwVcEH181a76LPO6ZwFPlHreFMgEFgGDo9uaEJlhuBHQILqtJ5AbfdwVmB19PBq4Nfq4PpALdIs+7wDMSvT7Sj+x+0mnaagl+ZwU/fk6+vwAIh9EnwHXmtkZ0e2dotvXAyHglTKvs2u68GlE1gEoz2seWTNhrkVWnQM4Bngpun21mX1SSawvlnrcEXjRzNoR+XBdXME5w4C+ZiUzETcxsyx331rqmHbA2grOP7LU3/N/wL2ltv80+vh54P5yzp0F3G9m/wO85e6fm1l/4Ad3/wrA3bdApPUAPGxmA4nU70HlvN5JwCGlWkxNifybLAbygPYV/A2SBpQIJJYMuNvdH99jY2Rhl2HAke6eb2YTiCyJCVDg7qEyr1MY/R2i4vdsYanHVuZ3VWwv9fjvRJYvfSMa6+0VnFOHyN+wo5LX3cHuv21fqjzxl7t/Z2aHASOAu83sfSKXcMp7jeuBNcCAaMwF5RxjRFpe75WzrwGRv0PSlO4RSCy9B1xmZgcAmFkHM2tN5NvmxmgS6A0cEaPyvwDOit4raEPkZm9VNAVWRh9fXGr7ViCr1PP3icw8CUD0G3dZ84AeFZQzkci0xRC5Bv9F9PFkIpd+KLV/D2bWHsh3938SaTEcCnwLtDezwdFjsqI3v5sSaSmEgVFE1tMt6z3gajOrFz33oGhLAiItiEp7F0lqUyKQmHH394lc2phkZrOAl4l8kL4L1DWzb4A7iHzwxcIrRBYOmQ08DkwBNlfhvNuBl8zsc2Bdqe1vAmfsulkMXAvkRG+uzqWclafc/VsiSzZmld0XPf/SaD2MAq6Lbv818Bszm0rk0lJ5MfcHpprZDOAW4M/uXgScB/zdzGYCHxD5Nv8IcLGZTSbyob69nNd7EpgLTI92KX2c3a2v44G3yzlH0oSmoZa0ZmYHuPs2i6wVOxU42t1XxzmG64Gt7v5kFY9vBOxwdzez84ncOD49pkFWHs9nRBZk35ioGCS2dI9A0t1bZtaMyE3fO+KdBKIeBc6pxvGHEbm5a8AmIj2KEsLMsoncL1ESSGNqEYiIBJzuEYiIBJwSgYhIwCkRiIgEnBKBiEjAKRGIiAScEoGISMD9P7m72JfE965sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16d069a8f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(end_lr = 1000, stepper=TransformStepper)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b577fe8f7b5e41979feba487e9958a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                                                         \n",
      "    0      1.927851   2.254671  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2546705476389852]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=1, use_clr=(20,10), stepper=TransformStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('transformer_10_6_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e3e10dd9bf43d099ea270975ff884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                                                         \n",
      "    0      1.794239   2.185134  \n",
      "    1      1.710947   2.087145                                                                                         \n",
      "    2      1.632631   2.031039                                                                                         \n",
      "    3      1.632101   1.989288                                                                                         \n",
      "    4      1.600255   1.954984                                                                                         \n",
      "    5      1.734163   1.934943                                                                                         \n",
      "    6      1.589054   1.911329                                                                                         \n",
      "    7      1.56047    1.897814                                                                                         \n",
      "    8      1.557043   1.890664                                                                                         \n",
      "    9      1.533074   1.88371                                                                                          \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8837101832480982]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr/5, 1, cycle_len=10, use_clr=(20,10), stepper=TransformStepper, cycle_save_name='transformer_10_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('transformer_10_6_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has trained down nicely. Lets try some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = V(x.transpose(0, 1))\n",
    "trg = V(y.transpose(0, 1))\n",
    "\n",
    "trg_input = trg[:, :-1]\n",
    "targets = trg[:, 1:].contiguous()\n",
    "\n",
    "src_mask, trg_mask = create_masks(src, trg_input)\n",
    "\n",
    "m = learn.model.eval()\n",
    "\n",
    "output = m(src, trg_input, src_mask, trg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = to_np(F.softmax(output).max(2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le secteur du pressage et de la trituration des huiles en inde s' est donc retrouvé avec une grande capacité de production inutilisée ( le taux d' utilisation est estimé à seulement 35 % ) et le pays avec un déficit grandissant en approvisionnement en huiles comestibles , qui a été contrebalancé par les importations .\n",
      "this situation has left india 's crushing and oil refining industry with large amounts of idle capacity ( utilization rate is estimated at only 35 % ) and the country with a burgeoning supply deficit in edible oils , which is balanced off with imports . \n",
      " _eos_\n",
      "resulted resulted been way 's pressing sector _eos_ crush force 's unused of unused output ( the is is estimated at only 35 % ) and has country 's growing edible deficit edible oils was offset was offset against against imports exceeding \n",
      " _bos_\n",
      "\n",
      "les détaillants mentionnent le bas niveau d’ achat des produits internationaux en comparaison aux produits chinois bien connus comme la raison de limiter l’ espace d’ étalage pour les produits étrangers . \n",
      " _eos_\n",
      "to facilitate successful market entry , canadian exporters are encouraged to develop market entry strategies that include working with local importers and distributors to develop a presence , gain valuable market advice , and best position products to meet local tastes , laws and pricing . \n",
      " _eos_\n",
      "export development patterns retailers exporters are able about obtain or intelligence points for enable developing with exporters processors . wholesalers . develop innovative dynamic rate i.e. practical insight share . product develop practices profiles demands and / needs and frameworks \n",
      " _bos_\n",
      "\n",
      "l' eau est vendue 160 yen ( _unk ) pour une bouteille de 410 ml tandis que la lotion coûte 892 yen ( _unk ) . coca-cola japan co . a également introduit au japon un nouveau diet coke avant de le commercialiser aux etats - unis . \n",
      " _eos_\n",
      "the water is sold at 160 yen ( _unk ) for a 410 ml bottle while the lotion is priced at 892 yen ( _unk ) . coca - cola japan co. also introduced a new diet coke in japan ahead of its release in the us .\n",
      "water is sold 160 160 yen ( _eos_ ) for 410 410 ml ml whereas 's 's _eos_ cost 750 750 yen ( _eos_ ) . report - cola co. co. also introduced a new groceries before addition from of united united in united united dollars\n",
      "\n",
      "exigences obligatoires en matière d' étiquetage des produits alimentaires importés l' avis n° 44 du ministère du commerce ( _unk ) / 1997 - 2002 , en date du 24 novembre 2000 , stipule que tous les produits alimentaires emballés importés en inde doivent mentionner les renseignements suivants : \n",
      " _eos_\n",
      "mandatory labeling requirements of imported food according to the notification no . 44 ( _unk ) / 1997 - 2002 , issued by the department of commerce on november 24 , 2000 , all packaged  ",
      " commodities imported into india should carry the following declarations : \n",
      " _eos_\n",
      "requirements requirements imported imported foodstuffs labelling to stelco department # . 44 of ) / 1997 - 2002 department dated as november november of commerce november november 24 , 2000 , states packaged foodstuffs foodstuffs imported into india must acknowledge out following information : \n",
      " _bos_\n",
      "\n",
      "exigences juridiques en matière de production d ' t_up ogm aucune activité de production dans laquelle des organismes , cellules ou microorganismes génétiquement modifiés sont créés ou utilisés ne peut être entreprise sans l' assentiment du comité d' approbation des produits transgéniques , si elle peut entraîner la libération d' organismes ou cellules génétiquement modifiés dans\n",
      "legal requirements for production of gmos production in which genetically engineered organisms or cells or micro- organisms are generated or used shall not be commenced except with the consent of genetic engineering approval committee with respect of discharge of genetically engineered organisms or cells into the environment .\n",
      "requirements concerning gmos of gmos none of which genetically modified organisms / organisms or organisms gmos are created nor used may not be undertaken without governed approval approval of gmos approval committee purposes respect to genetically from genetically modified organisms or cells into genetically body tk_rep\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[i,:] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions aren't that great. The model seems to do a good job of getting the general topic of the sentence it is translating, but the translations don't read well. The model seems to have a problem with repeating words. Then again the model is certainly better than just random guessing.\n",
    "\n",
    "But the important thing to note is that these predictions were generated using the target sentence and target mask as input to the model. How will the model perform without those?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encoder(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decoder(Variable(ys), memory, src_mask, Variable(subsequent_mask(ys.size(1)).type_as(src.data)))\n",
    "        prob = F.softmax(model.out(out[:, -1]))\n",
    "        #_, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = torch.multinomial(prob, 1)\n",
    "        next_word = next_word.data[0][0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = greedy_decode(m, src[10].unsqueeze(0), src_mask[10], enlen_90, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le secteur du pressage et de la trituration des huiles en inde s' est donc retrouvé avec une grande capacité de production inutilisée ( le taux d' utilisation est estimé à seulement 35 % ) et le pays avec un déficit grandissant en approvisionnement en huiles comestibles , qui a été contrebalancé par les importations .\n",
      "\n",
      "this situation has left india 's crushing and oil refining industry with large amounts of idle capacity ( utilization rate is estimated at only 35 % ) and the country with a burgeoning supply deficit in edible oils , which is balanced off with imports . \n",
      " _eos_\n",
      "\n",
      "_bos_ or oil demand growth in india has been adversely reduced because of the high production capacity ( i.e. from the use rate in only 35 per cent ) and the destination growing before _unk edible oils ( t_up cad _unk ) was higher . \n",
      " _eos_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([fr_itos[o] for o in x[:,10] if o != 1]))\n",
    "print()\n",
    "print(' '.join([en_itos[o] for o in y[:,10] if o != 1]))\n",
    "print()\n",
    "print(' '.join([en_itos[o] for o in ys[0] if o!=1]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly better than I expected. This translation is on par with the previous ones generated with the target sentence as input. My fear that the model would simply learn to copy the input target sentence seems overblown. Sure the translation is totally wrong, but it's as wrong as the translation with the target as input.\n",
    "\n",
    "This particular translation is really interesting to read. The source sentence says that India's oil refineries are operating at low capacity due to a supply deficit - a lack of oil. The model's translation suggests that *demand* for oil has been reduced due to high production capacity. The model picked up on the concepts of low production utilization, but attributed that to high capacity rather than supply shortage. Perhaps the phrasing 'large amounts of idle capacity' gave the model the impression that capacity is large. The model also flipped the concept of supply to that of demand. Another neural net mystery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model With Pretraining\n",
    "\n",
    "Now we're going to train the exact same model, but initialize the embedding layers with word vectors from fastText. Will this make the model better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 300\n",
    "heads = 10\n",
    "N = 6\n",
    "\n",
    "src_vocab = len(fr_itos)\n",
    "trg_vocab = len(en_itos)\n",
    "model = to_gpu(Transformer(src_vocab, trg_vocab, d_model, N, heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model with a xavier uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add in fastText word vectors for English and French words in our vocabulary that are represented in fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs = ft.load_model(str((PATH/'wiki.en.bin')))\n",
    "fr_vecs = ft.load_model(str((PATH/'wiki.fr.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl','wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = get_vecs('en', en_vecs)\n",
    "fr_vecd = get_vecs('fr', fr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "fr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = []\n",
    "for i,w in enumerate(fr_itos):\n",
    "    try: model.encoder.embed.embed.weight.data[i] = V(torch.from_numpy(fr_vecd[w]), requires_grad=True)\n",
    "    except: miss.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9147"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = []\n",
    "for i,w in enumerate(en_itos):\n",
    "    try: model.encoder.embed.embed.weight.data[i] = V(torch.from_numpy(en_vecd[w]), requires_grad=True)\n",
    "    except: miss.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10641"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So about 20% of our vocabulary wasn't represented in fastText, but that's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.9, 0.98))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, SingleModel(to_gpu(model)), opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adb9bb377574fe0bb1cbaec6311fcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|███████████████████▊                 | 13713/25687 [44:43<39:03,  5.11it/s, loss=tensor(15.5303, device='cuda:0')]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29464bbe5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(end_lr = 1000, stepper=TransformStepper)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f56740ece74b759f8feeca2dfc9848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                                                         \n",
      "    0      1.839402   2.244855  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.24485490753874]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=1, use_clr=(20,10), stepper=TransformStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('transformer_10_6_pre_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('transformer_10_6_pre_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa278c92775480bbde388ee9819098d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                                                         \n",
      "    0      1.826812   2.169857  \n",
      "    1      1.69769    2.071146                                                                                         \n",
      "    2      1.623587   2.012601                                                                                         \n",
      "    3      1.55745    1.970936                                                                                         \n",
      "    4      1.561492   1.938948                                                                                         \n",
      "    5      1.532702   1.907762                                                                                         \n",
      "    6      1.669025   1.896485                                                                                         \n",
      "    7      1.531949   1.877373                                                                                         \n",
      "    8      1.502228   1.867952                                                                                         \n",
      "    9      1.507128   1.863664                                                                                         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8636644344632247]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr/5, 1, cycle_len=10, use_clr=(20,10), stepper=TransformStepper, cycle_save_name='transformer_10_6_pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('transformer_10_6_pre_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pretrained word vectors doesn't seem to have had much of an effect here. The final validation loss for this model is 1.86, down from 1.88."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = V(x.transpose(0, 1))\n",
    "trg = V(y.transpose(0, 1))\n",
    "\n",
    "trg_input = trg[:, :-1]\n",
    "targets = trg[:, 1:].contiguous()\n",
    "\n",
    "src_mask, trg_mask = create_masks(src, trg_input)\n",
    "\n",
    "m = learn.model.eval()\n",
    "\n",
    "output = m(src, trg_input, src_mask, trg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = to_np(F.softmax(output).max(2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le secteur du pressage et de la trituration des huiles en inde s' est donc retrouvé avec une grande capacité de production inutilisée ( le taux d' utilisation est estimé à seulement 35 % ) et le pays avec un déficit grandissant en approvisionnement en huiles comestibles , qui a été contrebalancé par les importations .\n",
      "this situation has left india 's crushing and oil refining industry with large amounts of idle capacity ( utilization rate is estimated at only 35 % ) and the country with a burgeoning supply deficit in edible oils , which is balanced off with imports . \n",
      " _eos_\n",
      "resulted has resulted itself 's oil sector oil crush sector great unused of production utilization rate is estimated at only 35 % ) , has country has growing growing deficit deficit in edible oils which which has imports against by imports per \n",
      " _bos_\n",
      "\n",
      "les détaillants mentionnent le bas niveau d’ achat des produits internationaux en comparaison aux produits chinois bien connus comme la raison de limiter l’ espace d’ étalage pour les produits étrangers . \n",
      " _eos_\n",
      "to facilitate successful market entry , canadian exporters are encouraged to develop market entry strategies that include working with local importers and distributors to develop a presence , gain valuable market advice , and best position products to meet local tastes , laws and pricing . \n",
      " _eos_\n",
      "address _bos_ implementation intelligence processes retailers retailers can encouraged _eos_ _bos_ intelligence . assist markets _eos_ customers enterprises alike distributors . identify their viable - especially direction feedback share regarding advantage help practices paper across meet customers needs . preferences , expectations conditions \n",
      " _bos_\n",
      "\n",
      "l' eau est vendue 160 yen ( _unk ) pour une bouteille de 410 ml tandis que la lotion coûte 892 yen ( _unk ) . coca-cola japan co . a également introduit au japon un nouveau diet coke avant de le commercialiser aux etats - unis . \n",
      " _eos_\n",
      "the water is sold at 160 yen ( _unk ) for a 410 ml bottle while the lotion is priced at 892 yen ( _unk ) . coca - cola japan co. also introduced a new diet coke in japan ahead of its release in the us .\n",
      "water is sold 160 160 yen ( _eos_ ) pour 410 ml while yen costs yen yen ( _unk co. - japan co. also introduced a fresh diet before before advance before of marketing way into united united area\n",
      "\n",
      "exigences obligatoires en matière d' étiquetage des produits alimentaires importés l' avis n° 44 du ministère du commerce ( _unk ) / 1997 - 2002 , en date du 24 novembre 2000 , stipule que tous les produits alimentaires emballés importés en inde doivent mentionner les renseignements suivants : \n",
      " _eos_\n",
      "mandatory labeling requirements of imported food according to the notification no . 44 ( _unk ) / 1997 - 2002 , issued by the department of commerce on november 24 , 2000 , all packaged  ",
      " commodities imported into india should carry the following declarations : \n",
      " _eos_\n",
      "labelling requirements imported imported foodstuffs products to memorandum department # . 44 ministry ) / / 2002 dated dated november november department of commerce dated november 24 , 2000 states packaged food packaged imported into india shall include out following information : \n",
      " _bos_\n",
      "\n",
      "exigences juridiques en matière de production d ' t_up ogm aucune activité de production dans laquelle des organismes , cellules ou microorganismes génétiquement modifiés sont créés ou utilisés ne peut être entreprise sans l' assentiment du comité d' approbation des produits transgéniques , si elle peut entraîner la libération d' organismes ou cellules génétiquement modifiés dans\n",
      "legal requirements for production of gmos production in which genetically engineered organisms or cells or micro- organisms are generated or used shall not be commenced except with the consent of genetic engineering approval committee with respect of discharge of genetically engineered organisms or cells into the environment .\n",
      "requirements for gmos gmos gmos no none excess genetically modified organisms / organisms are organisms organisms created or used shall not be undertaken without without approval approval of gmos products committee committee respect to ge organisms genetically modified organisms or cells into organisms body governing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[i,:] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions seem about the same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = greedy_decode(m, src[10].unsqueeze(0), src_mask[10], enlen_90, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le secteur du pressage et de la trituration des huiles en inde s' est donc retrouvé avec une grande capacité de production inutilisée ( le taux d' utilisation est estimé à seulement 35 % ) et le pays avec un déficit grandissant en approvisionnement en huiles comestibles , qui a été contrebalancé par les importations .\n",
      "\n",
      "this situation has left india 's crushing and oil refining industry with large amounts of idle capacity ( utilization rate is estimated at only 35 % ) and the country with a burgeoning supply deficit in edible oils , which is balanced off with imports . \n",
      " _eos_\n",
      "\n",
      "_bos_ and affected using oil oils grown in india was then found to us with great anywhere in balance ( use is estimated at only 35 % ) and the country has become growing deficit in edible oils and gm imports . \n",
      " _eos_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([fr_itos[o] for o in x[:,10] if o != 1]))\n",
    "print()\n",
    "print(' '.join([en_itos[o] for o in y[:,10] if o != 1]))\n",
    "print()\n",
    "print(' '.join([en_itos[o] for o in ys[0] if o!=1]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 30\n",
    "ys = greedy_decode(m, src[j].unsqueeze(0), src_mask[10], enlen_90, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selon le professeur hamm de l' université de _unk , il pourrait devenir nécessaire pour les fournisseurs allemands d' aliments biologiques de recourir à l' importation de l' amérique latine ou du canada , mais , pour de nombreux adeptes , cela serait contraire au principe de la consommation de produits saisonniers produits localement de manière\n",
      "\n",
      "_unk university 's hamm said germany 's organic food suppliers may have to fall back on imports from latin america or canada but for many fans this runs contrary to the philosophy of using seasonal foods grown close to home and in harmony with nature . \n",
      " _eos_\n",
      "\n",
      "_bos_ holds an at university of _unk that might be necessary for german organic food suppliers to use imports of latin america or canada , but not many gm oriented products in this manner should be reasonable to demand in the economy . \n",
      " _eos_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([fr_itos[o] for o in x[:,j] if o != 1]))\n",
    "print()\n",
    "print(' '.join([en_itos[o] for o in y[:,j] if o != 1]))\n",
    "print()\n",
    "print(' '.join([en_itos[o] for o in ys[0] if o!=1]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
